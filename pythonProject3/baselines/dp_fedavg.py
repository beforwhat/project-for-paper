# baselines/dp_fedavg.py
"""
å¸¦å·®åˆ†éšç§çš„FedAvgï¼ˆDP-FedAvgï¼‰ç®—æ³•å®ç°
æ ¸å¿ƒå®šä½ï¼šFedAvgåŸºç¡€ä¸Šæ–°å¢å·®åˆ†éšç§ä¿æŠ¤ï¼Œä½œä¸ºéšç§ä¿æŠ¤ç±»è”é‚¦ç®—æ³•çš„åŸºå‡†
æ ¸å¿ƒé€»è¾‘ï¼š
1. å®¢æˆ·ç«¯ï¼ˆDPFedAvgClientï¼‰ï¼šç»§æ‰¿FedAvgClientï¼Œä»…åœ¨æœ¬åœ°è®­ç»ƒçš„æ¢¯åº¦ç¯èŠ‚åŠ å…¥ã€Œè‡ªé€‚åº”è£å‰ª+é«˜æ–¯å™ªå£°ã€ï¼›
2. æœåŠ¡ç«¯ï¼ˆDPFedAvgServerï¼‰ï¼šå®Œå…¨å¤ç”¨FedAvgServerçš„ç­‰æƒé‡èšåˆé€»è¾‘ï¼Œæ— ä»»ä½•ä¿®æ”¹ï¼›
è®¾è®¡åŸåˆ™ï¼š
- ä»…æ–°å¢DPç›¸å…³é€»è¾‘ï¼Œå…¶ä½™å®Œå…¨å¤ç”¨FedAvgï¼ˆä¿è¯ä¸åŸºç¡€FedAvgçš„å”¯ä¸€å·®å¼‚æ˜¯DPï¼‰ï¼›
- å¤ç”¨é¡¹ç›®æ ¸å¿ƒçš„AdaptiveClippingDPæ¨¡å—ï¼ˆè‡ªé€‚åº”è£å‰ªï¼‰ï¼Œä¿è¯DPé€»è¾‘çš„ä¸€è‡´æ€§ï¼›
- æ¥å£ä¸FedAvgå®Œå…¨å¯¹é½ï¼Œä¾¿äºå…¬å¹³å¯¹æ¯”ï¼ˆä»…å¤šDPé…ç½®é¡¹ï¼‰ã€‚
"""
import torch
import torch.optim as optim
import torch.nn.functional as F
from tqdm import tqdm

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from baselines.fedavg import FedAvgClient, FedAvgServer  # å¤ç”¨åŸºç¡€FedAvg
from core.dp.adaptive_clipping_dp import AdaptiveClippingDP  # å¤ç”¨è‡ªé€‚åº”è£å‰ªDPæ¨¡å—
from configs.config_loader import load_config

class DPFedAvgClient(FedAvgClient):
    """
    DP-FedAvgå®¢æˆ·ç«¯ï¼šç»§æ‰¿FedAvgClientï¼Œä»…æ–°å¢æ¢¯åº¦çš„DPä¿æŠ¤ï¼ˆè‡ªé€‚åº”è£å‰ª+åŠ å™ªï¼‰
    æ ¸å¿ƒä¿®æ”¹ï¼šlocal_trainæ–¹æ³•ä¸­ï¼Œåå‘ä¼ æ’­åå¯¹æ¢¯åº¦åšDPå¤„ç†ï¼Œå†æ‰§è¡Œä¼˜åŒ–å™¨step
    """
    def __init__(self, client_id: int, config=None):
        """
        åˆå§‹åŒ–DP-FedAvgå®¢æˆ·ç«¯ï¼ˆå¤ç”¨FedAvgClientåˆå§‹åŒ–ï¼Œæ–°å¢DPä¼˜åŒ–å™¨ï¼‰
        Args:
            client_id: å®¢æˆ·ç«¯å”¯ä¸€æ ‡è¯†
            config: é…ç½®å¯¹è±¡ï¼ˆéœ€åŒ…å«dpç›¸å…³é…ç½®ï¼šepsilon/delta/clip_thresholdç­‰ï¼‰
        """
        super().__init__(client_id=client_id, config=config)
        
        # åˆå§‹åŒ–è‡ªé€‚åº”è£å‰ªDPä¼˜åŒ–å™¨ï¼ˆæ ¸å¿ƒæ–°å¢ï¼šDPéšç§ä¿æŠ¤ï¼‰
        self.dp_optimizer = AdaptiveClippingDP(config=config)
        
        print(f"âœ… DPFedAvgå®¢æˆ·ç«¯ [{self.client_id}] åˆå§‹åŒ–å®Œæˆï¼ˆåŸºäºFedAvg + è‡ªé€‚åº”è£å‰ªDPï¼‰")
        print(f"ğŸ“Œ DPé…ç½®ï¼šÎµ={self.config.dp.epsilon} | Î´={self.config.dp.delta} | åŸºç¡€è£å‰ªé˜ˆå€¼={self.config.dp.base_clip_threshold}")

    def local_train(self):
        """
        é‡å†™FedAvgClientçš„local_trainï¼šä»…æ–°å¢æ¢¯åº¦çš„DPä¿æŠ¤æ­¥éª¤
        æ ¸å¿ƒæµç¨‹ï¼šå‰å‘ä¼ æ’­â†’æŸå¤±è®¡ç®—â†’åå‘ä¼ æ’­â†’DPæ¢¯åº¦å¤„ç†â†’æ¢¯åº¦ä¸‹é™
        """
        # 1. åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒï¼ˆå®Œå…¨å¤ç”¨FedAvgçš„é€»è¾‘ï¼‰
        self.local_model.train()
        optimizer = optim.SGD(
            self.local_model.parameters(),
            lr=self.config.fed.local_lr,
            momentum=self.config.fed.momentum
        )
        loss_fn = F.cross_entropy if self.config.model.num_classes > 2 else F.binary_cross_entropy_with_logits

        # 2. æœ¬åœ°è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒæ–°å¢DPæ¢¯åº¦å¤„ç†ï¼‰
        for epoch in range(self.config.fed.local_epochs):
            epoch_loss = 0.0
            total_samples = 0
            pbar = tqdm(self.local_dataloader, desc=f"DPFedAvgå®¢æˆ·ç«¯ [{self.client_id}] è®­ç»ƒEpoch {epoch+1}")
            
            for batch_idx, (images, labels) in enumerate(pbar):
                images, labels = images.to(self.device), labels.to(self.device)
                
                # å‰å‘ä¼ æ’­ï¼ˆå¤ç”¨FedAvgï¼‰
                optimizer.zero_grad()
                outputs = self.local_model(images)
                loss = loss_fn(outputs, labels)
                
                # åå‘ä¼ æ’­ï¼ˆå¤ç”¨FedAvgï¼‰
                loss.backward()

                # ==============================================
                # æ ¸å¿ƒæ–°å¢ï¼šDPæ¢¯åº¦ä¿æŠ¤ï¼ˆè‡ªé€‚åº”è£å‰ª + é«˜æ–¯å™ªå£°ï¼‰
                # ==============================================
                # æå–å½“å‰æ¢¯åº¦ï¼ˆæŒ‰å‚æ•°åå­˜å‚¨ï¼‰
                current_gradient_dict = {}
                for name, param in self.local_model.named_parameters():
                    if param.grad is not None:
                        current_gradient_dict[name] = param.grad.clone()
                
                # è‡ªé€‚åº”è£å‰ª + æ·»åŠ DPå™ªå£°
                protected_gradient_dict = self.dp_optimizer.adaptive_clip_and_add_noise(
                    model=self.local_model,
                    current_gradient_dict=current_gradient_dict
                )
                
                # æ›¿æ¢ä¸ºå¸¦DPä¿æŠ¤çš„æ¢¯åº¦
                for name, param in self.local_model.named_parameters():
                    if name in protected_gradient_dict:
                        param.grad = protected_gradient_dict[name]
                # ==============================================

                # æ¢¯åº¦ä¸‹é™ï¼ˆå¤ç”¨FedAvgï¼‰
                optimizer.step()
                
                # ç»Ÿè®¡æŸå¤±ï¼ˆå¤ç”¨FedAvgï¼‰
                epoch_loss += loss.item() * images.size(0)
                total_samples += images.size(0)
                pbar.set_postfix({"batch_loss": loss.item(), "avg_loss": epoch_loss/total_samples})

        # 3. è®­ç»ƒå®Œæˆï¼Œè®°å½•æŸå¤±ï¼ˆå¤ç”¨FedAvgï¼‰
        self.local_train_loss = epoch_loss / total_samples
        print(f"\nğŸ“Œ DPFedAvgå®¢æˆ·ç«¯ [{self.client_id}] æœ¬åœ°è®­ç»ƒå®Œæˆ | å¹³å‡æŸå¤±ï¼š{self.local_train_loss:.4f}")

        # 4. è¿”å›æœ¬åœ°æ¨¡å‹å‚æ•°ï¼ˆå¤ç”¨FedAvgï¼‰
        return self.get_model_parameters()

class DPFedAvgServer(FedAvgServer):
    """
    DP-FedAvgæœåŠ¡ç«¯ï¼šå®Œå…¨å¤ç”¨FedAvgServerçš„ç­‰æƒé‡èšåˆé€»è¾‘
    æ ¸å¿ƒï¼šæœåŠ¡ç«¯æ— éœ€ä»»ä½•DPç›¸å…³å¤„ç†ï¼ˆDPä»…åœ¨å®¢æˆ·ç«¯ä¾§ï¼‰ï¼Œä¿è¯ä¸FedAvgçš„èšåˆé€»è¾‘ä¸€è‡´
    """
    def __init__(self, config=None):
        """
        åˆå§‹åŒ–DP-FedAvgæœåŠ¡ç«¯ï¼ˆå®Œå…¨å¤ç”¨FedAvgServerï¼‰
        Args:
            config: é…ç½®å¯¹è±¡ï¼ˆä»…éœ€FedAvgç›¸å…³é…ç½®ï¼Œæ— éœ€DPé…ç½®ï¼‰
        """
        super().__init__(config=config)
        print(f"âœ… DPFedAvgæœåŠ¡ç«¯åˆå§‹åŒ–å®Œæˆï¼ˆå®Œå…¨å¤ç”¨FedAvgç­‰æƒé‡èšåˆï¼Œæ— é¢å¤–ä¿®æ”¹ï¼‰")

# ======================== ç‹¬ç«‹æµ‹è¯•ç¤ºä¾‹ï¼ˆéªŒè¯DP-FedAvgåŠŸèƒ½ï¼‰ ========================
if __name__ == "__main__":
    """
    æµ‹è¯•DP-FedAvgæ ¸å¿ƒé€»è¾‘ï¼šå®¢æˆ·ç«¯å¸¦DPè®­ç»ƒ â†’ æœåŠ¡ç«¯ç­‰æƒé‡èšåˆ
    å¯¹æ¯”FedAvgï¼šä»…å®¢æˆ·ç«¯æ¢¯åº¦å¤šäº†DPå¤„ç†ï¼ŒæœåŠ¡ç«¯å®Œå…¨ä¸€è‡´
    """
    # 1. åŠ è½½é…ç½®ï¼ˆéœ€åŒ…å«dpé…ç½®ï¼‰
    config = load_config()
    # æµ‹è¯•ç”¨é…ç½®
    config.fed.num_clients = 2
    config.fed.local_epochs = 1
    config.fed.local_lr = 0.01
    config.dp.epsilon = 1.0
    config.dp.delta = 1e-5
    config.dp.base_clip_threshold = 1.0
    config.dp.sliding_window_size = 3
    config.dp.threshold_change_rate = 0.2

    # 2. åˆå§‹åŒ–DP-FedAvgæœåŠ¡ç«¯
    dp_fedavg_server = DPFedAvgServer(config=config)

    # 3. åˆå§‹åŒ–DP-FedAvgå®¢æˆ·ç«¯
    client_list = []
    for client_id in range(config.fed.num_clients):
        client = DPFedAvgClient(client_id=client_id, config=config)
        client_list.append(client)

    # 4. æ¨¡æ‹Ÿä¸€è½®è”é‚¦è®­ç»ƒ
    print("\n=== æ¨¡æ‹ŸDP-FedAvgä¸€è½®è”é‚¦è®­ç»ƒ ===")
    # 4.1 å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼ˆå¸¦DPï¼‰
    client_params_list = []
    for client in client_list:
        client_params = client.local_train()
        client_params_list.append(client_params)

    # 4.2 æœåŠ¡ç«¯èšåˆï¼ˆå¤ç”¨FedAvgç­‰æƒé‡ï¼‰
    dp_fedavg_server.aggregate_local_results(client_params_list=client_params_list)

    # 4.3 æ‰“å°ç»“æœ
    print("\n=== DP-FedAvgä¸€è½®è®­ç»ƒå®Œæˆ ===")
    print(f"æœåŠ¡ç«¯å…¨å±€æ¨¡å‹å‚æ•°ç¤ºä¾‹ï¼ˆconv1.weight.shapeï¼‰ï¼š{dp_fedavg_server.global_model.conv1.weight.shape}")
    for idx, client in enumerate(client_list):
        print(f"DP-FedAvgå®¢æˆ·ç«¯ [{idx}] æœ¬åœ°è®­ç»ƒæŸå¤±ï¼š{client.local_train_loss:.4f}")