# core/ala/ala_optimizer.py
"""
ALAä¼˜åŒ–å™¨ï¼ˆALAOptimizerï¼‰
æ ¸å¿ƒèŒè´£ï¼š
1.  ä¿ç•™åŸæœ‰ALAæ ¸å¿ƒé€»è¾‘ï¼šè‡ªé€‚åº”æœ¬åœ°èšåˆï¼ˆç¼“è§£å®¢æˆ·ç«¯å¼‚è´¨æ€§ï¼Œä¼˜åŒ–æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–/æ›´æ–°ï¼‰
2.  æ–°å¢æ ¸å¿ƒåŠŸèƒ½ï¼šextract_ala_features() æå–ä¸‰å¤§ç‰¹å¾ï¼ˆåå·®ã€ç¨³å®šæ€§ã€æ€§èƒ½ï¼‰ï¼Œæ”¯æ’‘SAè´¡çŒ®åº¦è®¡ç®—
3.  ç‰¹å¾å½’ä¸€åŒ–å¤„ç†ï¼Œä¿è¯ç‰¹å¾å€¼åœ¨[0,1]åŒºé—´ï¼Œæå‡SAè´¡çŒ®åº¦è®¡ç®—çš„ç¨³å®šæ€§
4.  ç‹¬ç«‹æ¨¡å—è®¾è®¡ï¼Œæ— ä¸šåŠ¡ä¾µå…¥ï¼Œä»…å¯¹å¤–æš´éœ²æ¥å£ï¼Œå…¼å®¹å®¢æˆ·ç«¯/æœåŠ¡ç«¯è°ƒç”¨
"""
import numpy as np
import torch
from copy import deepcopy

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from configs.config_loader import load_config
from models import get_model

class ALAOptimizer:
    """
    ALAï¼ˆAdaptive Local Aggregationï¼‰ä¼˜åŒ–å™¨
    æ ¸å¿ƒæ–¹æ³•ï¼š
    - ala_adaptive_update()ï¼šåŸæœ‰é€»è¾‘ï¼Œå®¢æˆ·ç«¯æ¨¡å‹è‡ªé€‚åº”æ›´æ–°
    - extract_ala_features()ï¼šæ–°å¢é€»è¾‘ï¼Œæå–SAè´¡çŒ®åº¦ç‰¹å¾
    """
    def __init__(self, config=None):
        """
        åˆå§‹åŒ–ALAä¼˜åŒ–å™¨
        Args:
            config: é…ç½®å¯¹è±¡ï¼ˆé»˜è®¤åŠ è½½å…¨å±€é…ç½®ï¼‰
        """
        # 1. åŸºç¡€é…ç½®åˆå§‹åŒ–
        self.config = config if config is not None else load_config()
        self.ala_alpha = self.config.fed.ala_alpha  # ALAè‡ªé€‚åº”æƒé‡ï¼ˆ0~1ï¼Œå…¨å±€é…ç½®ï¼‰
        self.device = self.config.device

        # 2. å®¢æˆ·ç«¯å†å²å‚æ•°ç¼“å­˜ï¼ˆæŒä¹…åŒ–ï¼Œç”¨äºALAæ›´æ–°å’Œç‰¹å¾è®¡ç®—ï¼‰
        # ç»“æ„ï¼š{client_id: {"prev_params": å†å²å‚æ•°åˆ—è¡¨, "prev_metrics": å†å²è®­ç»ƒæŒ‡æ ‡}}
        self.client_history = {}

        # 3. ç‰¹å¾è®¡ç®—è¶…å‚æ•°ï¼ˆä»é…ç½®è¯»å–ï¼Œé¿å…ç¡¬ç¼–ç ï¼‰
        self.feature_norm_range = (0.0, 1.0)  # ç‰¹å¾å½’ä¸€åŒ–èŒƒå›´
        self.stability_window = 3  # ç¨³å®šæ€§è®¡ç®—çš„æ»‘åŠ¨çª—å£ï¼ˆå–æœ€è¿‘Nè½®è®­ç»ƒæŒ‡æ ‡ï¼‰
        self.bias_norm_type = "cosine"  # åå·®è®¡ç®—æ–¹å¼ï¼šcosineï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰/l2ï¼ˆL2è·ç¦»ï¼‰

        print(f"âœ… ALAä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Œ ALAè‡ªé€‚åº”æƒé‡ï¼š{self.ala_alpha} | ç‰¹å¾å½’ä¸€åŒ–èŒƒå›´ï¼š{self.feature_norm_range}")
        print(f"ğŸ“Œ åå·®è®¡ç®—æ–¹å¼ï¼š{self.bias_norm_type} | ç¨³å®šæ€§æ»‘åŠ¨çª—å£ï¼š{self.stability_window}")

    # ==============================================
    # åŸæœ‰æ ¸å¿ƒé€»è¾‘ï¼šALAè‡ªé€‚åº”æœ¬åœ°èšåˆï¼ˆå®¢æˆ·ç«¯æ¨¡å‹åˆå§‹åŒ–/æ›´æ–°ï¼‰
    # ==============================================
    def ala_adaptive_update(self, client_id: int, local_model, global_model_params=None, epoch=None) -> torch.nn.Module:
        """
        åŸæœ‰ALAæ ¸å¿ƒé€»è¾‘ï¼šè‡ªé€‚åº”æ›´æ–°å®¢æˆ·ç«¯æœ¬åœ°æ¨¡å‹å‚æ•°
        é€»è¾‘ï¼šw_init = Î±*w_global + (1-Î±)*w_prevï¼ˆç¼“è§£å®¢æˆ·ç«¯å¼‚è´¨æ€§ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ï¼‰
        Args:
            client_id: å®¢æˆ·ç«¯å”¯ä¸€æ ‡è¯†
            local_model: å¾…æ›´æ–°çš„å®¢æˆ·ç«¯æœ¬åœ°æ¨¡å‹å®ä¾‹
            global_model_params: å…¨å±€æ¨¡å‹å‚æ•°ï¼ˆNoneåˆ™ä½¿ç”¨æœ¬åœ°æ¨¡å‹å½“å‰å‚æ•°ä½œä¸ºå‚è€ƒï¼‰
            epoch: å½“å‰æœ¬åœ°è®­ç»ƒè½®æ¬¡ï¼ˆç”¨äºæ›´æ–°å†å²ç¼“å­˜ï¼‰
        Returns:
            æ›´æ–°åçš„æœ¬åœ°æ¨¡å‹å®ä¾‹
        """
        # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯å†å²ç¼“å­˜ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶ï¼‰
        if client_id not in self.client_history:
            self.client_history[client_id] = {
                "prev_params": None,  # ä¸Šä¸€è½®æœ¬åœ°æ¨¡å‹å‚æ•°
                "prev_metrics": []    # ä¸Šå‡ è½®è®­ç»ƒæŒ‡æ ‡ï¼ˆloss/accï¼‰
            }

        # 2. è·å–å…¨å±€å‚æ•°ï¼ˆé»˜è®¤ä½¿ç”¨æœ¬åœ°æ¨¡å‹å½“å‰å‚æ•°ä½œä¸ºå‚è€ƒï¼‰
        if global_model_params is None:
            global_model_params = local_model.get_params()

        # 3. æ‰§è¡ŒALAè‡ªé€‚åº”æ›´æ–°
        local_params = local_model.get_params()
        prev_params = self.client_history[client_id]["prev_params"]

        if prev_params is None:
            # é¦–æ¬¡æ›´æ–°ï¼šæ— å†å²å‚æ•°ï¼Œç›´æ¥ä½¿ç”¨å…¨å±€å‚æ•°
            ala_updated_params = global_model_params
            print(f"ğŸ“Œ å®¢æˆ·ç«¯ [{client_id}] é¦–æ¬¡ALAæ›´æ–°ï¼Œä½¿ç”¨å…¨å±€å‚æ•°åˆå§‹åŒ–")
        else:
            # éé¦–æ¬¡æ›´æ–°ï¼šÎ±*å…¨å±€å‚æ•° + (1-Î±)*å†å²å‚æ•°
            ala_updated_params = []
            for g_param, p_param in zip(global_model_params, prev_params):
                updated_param = self.ala_alpha * np.array(g_param) + (1 - self.ala_alpha) * np.array(p_param)
                ala_updated_params.append(updated_param)
            print(f"ğŸ“Œ å®¢æˆ·ç«¯ [{client_id}] ALAæ›´æ–°å®Œæˆï¼ˆÎ±={self.ala_alpha}ï¼‰")

        # 4. åŠ è½½æ›´æ–°åçš„å‚æ•°åˆ°æœ¬åœ°æ¨¡å‹
        local_model.set_params(ala_updated_params)

        # 5. æ›´æ–°å®¢æˆ·ç«¯å†å²ç¼“å­˜ï¼ˆä¿å­˜å½“å‰å‚æ•°ï¼Œç”¨äºä¸‹ä¸€è½®æ›´æ–°ï¼‰
        if epoch is not None:
            self.client_history[client_id]["prev_params"] = deepcopy(local_model.get_params())

        return local_model

    # ==============================================
    # æ–°å¢æ ¸å¿ƒé€»è¾‘ï¼šæå–ALAç‰¹å¾ï¼ˆæ”¯æ’‘SAè´¡çŒ®åº¦è®¡ç®—ï¼‰
    # ==============================================
    def extract_ala_features(self, client_id: int, local_model, train_metrics: dict, global_model=None) -> dict:
        """
        æ–°å¢æ ¸å¿ƒæ–¹æ³•ï¼šæå–å®¢æˆ·ç«¯ALAä¸‰å¤§ç‰¹å¾ï¼ˆåå·®ã€ç¨³å®šæ€§ã€æ€§èƒ½ï¼‰ï¼Œæ”¯æ’‘SAè´¡çŒ®åº¦è®¡ç®—
        Args:
            client_id: å®¢æˆ·ç«¯å”¯ä¸€æ ‡è¯†
            local_model: å®¢æˆ·ç«¯æœ¬åœ°æ¨¡å‹å®ä¾‹
            train_metrics: å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒæŒ‡æ ‡ï¼ˆåŒ…å«train_loss/train_acc/local_sample_numï¼‰
            global_model: å…¨å±€æ¨¡å‹å®ä¾‹ï¼ˆNoneåˆ™è‡ªåŠ¨åˆå§‹åŒ–å…¨å±€æ¨¡å‹ç”¨äºåå·®è®¡ç®—ï¼‰
        Returns:
            å½’ä¸€åŒ–åçš„ALAç‰¹å¾å­—å…¸ï¼š
            {
                "bias_feature": åå·®ç‰¹å¾ï¼ˆ0~1ï¼Œè¶Šå°è¡¨ç¤ºä¸å…¨å±€åå·®è¶Šå°ï¼‰,
                "stability_feature": ç¨³å®šæ€§ç‰¹å¾ï¼ˆ0~1ï¼Œè¶Šå¤§è¡¨ç¤ºè®­ç»ƒè¶Šç¨³å®šï¼‰,
                "performance_feature": æ€§èƒ½ç‰¹å¾ï¼ˆ0~1ï¼Œè¶Šå¤§è¡¨ç¤ºæœ¬åœ°æ€§èƒ½è¶Šå¥½ï¼‰
            }
        """
        # å‰ç½®æ£€æŸ¥ï¼šå®¢æˆ·ç«¯å†å²ç¼“å­˜åˆå§‹åŒ–
        if client_id not in self.client_history:
            self.client_history[client_id] = {
                "prev_params": deepcopy(local_model.get_params()),
                "prev_metrics": [train_metrics]
            }
        else:
            # æ›´æ–°å†å²è®­ç»ƒæŒ‡æ ‡ï¼ˆç”¨äºç¨³å®šæ€§è®¡ç®—ï¼‰
            self.client_history[client_id]["prev_metrics"].append(train_metrics)

        # æ­¥éª¤1ï¼šè®¡ç®—åå·®ç‰¹å¾ï¼ˆæœ¬åœ°æ¨¡å‹ vs å…¨å±€æ¨¡å‹ï¼‰
        bias_feature = self._calculate_bias_feature(local_model, global_model)

        # æ­¥éª¤2ï¼šè®¡ç®—ç¨³å®šæ€§ç‰¹å¾ï¼ˆæœ¬åœ°è®­ç»ƒæŒ‡æ ‡çš„æ³¢åŠ¨ç¨‹åº¦ï¼‰
        stability_feature = self._calculate_stability_feature(client_id, train_metrics)

        # æ­¥éª¤3ï¼šè®¡ç®—æ€§èƒ½ç‰¹å¾ï¼ˆæœ¬åœ°è®­ç»ƒçš„æœ€ç»ˆå‡†ç¡®ç‡/æŸå¤±ï¼‰
        performance_feature = self._calculate_performance_feature(train_metrics)

        # æ­¥éª¤4ï¼šç‰¹å¾å½’ä¸€åŒ–ï¼ˆç»Ÿä¸€åˆ°[0,1]åŒºé—´ï¼Œæ–¹ä¾¿SAè´¡çŒ®åº¦èåˆï¼‰
        normalized_features = self._normalize_features({
            "bias_feature": bias_feature,
            "stability_feature": stability_feature,
            "performance_feature": performance_feature
        })

        # æ‰“å°ç‰¹å¾ç»“æœï¼ˆè¾…åŠ©è°ƒè¯•ï¼‰
        print(f"\nğŸ“Š å®¢æˆ·ç«¯ [{client_id}] ALAç‰¹å¾æå–å®Œæˆï¼š")
        print(f"   åå·®ç‰¹å¾ï¼ˆå½’ä¸€åŒ–ï¼‰ï¼š{normalized_features['bias_feature']:.4f}")
        print(f"   ç¨³å®šæ€§ç‰¹å¾ï¼ˆå½’ä¸€åŒ–ï¼‰ï¼š{normalized_features['stability_feature']:.4f}")
        print(f"   æ€§èƒ½ç‰¹å¾ï¼ˆå½’ä¸€åŒ–ï¼‰ï¼š{normalized_features['performance_feature']:.4f}")

        return normalized_features

    # ==============================================
    # è¾…åŠ©æ–¹æ³•ï¼šè®¡ç®—åå·®ç‰¹å¾ï¼ˆæœ¬åœ° vs å…¨å±€ï¼‰
    # ==============================================
    def _calculate_bias_feature(self, local_model, global_model=None) -> float:
        """
        è®¡ç®—åå·®ç‰¹å¾ï¼šè¡¡é‡æœ¬åœ°æ¨¡å‹ä¸å…¨å±€æ¨¡å‹çš„å‚æ•°å·®å¼‚
        - cosineæ–¹å¼ï¼šä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆ1-ç›¸ä¼¼åº¦ï¼Œå€¼è¶Šå°åå·®è¶Šå°ï¼‰
        - l2æ–¹å¼ï¼šL2è·ç¦»ï¼ˆå½’ä¸€åŒ–åï¼Œå€¼è¶Šå°åå·®è¶Šå°ï¼‰
        """
        # åˆå§‹åŒ–å…¨å±€æ¨¡å‹ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„åŸºç¡€æ¨¡å‹ï¼‰
        if global_model is None:
            global_model = get_model(config=self.config)
            global_model = global_model.to(self.device)

        # æå–æœ¬åœ°/å…¨å±€æ¨¡å‹å‚æ•°ï¼ˆå±•å¹³ä¸ºä¸€ç»´æ•°ç»„ï¼Œä¾¿äºè®¡ç®—ï¼‰
        local_params_flat = self._flatten_params(local_model.get_params())
        global_params_flat = self._flatten_params(global_model.get_params())

        # é¿å…é™¤é›¶é”™è¯¯ï¼ˆå‚æ•°å…¨é›¶ï¼‰
        if np.linalg.norm(local_params_flat) == 0 or np.linalg.norm(global_params_flat) == 0:
            return 1.0  # æœ€å¤§åå·®

        # æŒ‰æŒ‡å®šæ–¹å¼è®¡ç®—åå·®
        if self.bias_norm_type == "cosine":
            # ä½™å¼¦ç›¸ä¼¼åº¦ï¼šèŒƒå›´[-1,1] â†’ è½¬æ¢ä¸ºåå·®[0,1]ï¼ˆ1 - (ç›¸ä¼¼åº¦+1)/2ï¼‰
            cos_sim = np.dot(local_params_flat, global_params_flat) / (np.linalg.norm(local_params_flat) * np.linalg.norm(global_params_flat))
            bias = 1 - ((cos_sim + 1) / 2)  # è½¬æ¢ä¸º0~1ï¼Œè¶Šå°åå·®è¶Šå°
        elif self.bias_norm_type == "l2":
            # L2è·ç¦»ï¼šå½’ä¸€åŒ–åˆ°0~1
            l2_dist = np.linalg.norm(local_params_flat - global_params_flat)
            bias = l2_dist / (np.linalg.norm(local_params_flat) + np.linalg.norm(global_params_flat))  # å½’ä¸€åŒ–
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åå·®è®¡ç®—æ–¹å¼ï¼š{self.bias_norm_type}ï¼Œå¯é€‰cosine/l2")

        return bias

    # ==============================================
    # è¾…åŠ©æ–¹æ³•ï¼šè®¡ç®—ç¨³å®šæ€§ç‰¹å¾ï¼ˆè®­ç»ƒæŒ‡æ ‡æ³¢åŠ¨ï¼‰
    # ==============================================
    def _calculate_stability_feature(self, client_id: int, train_metrics: dict) -> float:
        """
        è®¡ç®—ç¨³å®šæ€§ç‰¹å¾ï¼šè¡¡é‡æœ¬åœ°è®­ç»ƒè¿‡ç¨‹ä¸­æŒ‡æ ‡çš„æ³¢åŠ¨ç¨‹åº¦
        - è®¡ç®—æœ€è¿‘Nè½®loss/accçš„æ–¹å·®ï¼Œæ–¹å·®è¶Šå°â†’ç¨³å®šæ€§è¶Šé«˜â†’ç‰¹å¾å€¼è¶Šå¤§
        """
        # è·å–å®¢æˆ·ç«¯å†å²è®­ç»ƒæŒ‡æ ‡
        history_metrics = self.client_history[client_id]["prev_metrics"]
        # å–æœ€è¿‘stability_windowè½®æŒ‡æ ‡ï¼ˆä¸è¶³åˆ™å–å…¨éƒ¨ï¼‰
        recent_metrics = history_metrics[-self.stability_window:]

        if len(recent_metrics) < 2:
            # åªæœ‰1è½®æŒ‡æ ‡ï¼šæ— æ³•è®¡ç®—æ–¹å·®ï¼Œé»˜è®¤ç¨³å®šæ€§æœ€é«˜ï¼ˆ1.0ï¼‰
            return 1.0

        # æå–æœ€è¿‘è½®æ¬¡çš„å‡†ç¡®ç‡ï¼ˆä¹Ÿå¯ç»“åˆlossï¼Œè¿™é‡Œä¼˜å…ˆç”¨accï¼‰
        recent_accs = [m["train_acc"][-1] for m in recent_metrics]  # æ¯è½®æœ€åä¸€ä¸ªacc
        # è®¡ç®—æ–¹å·®ï¼ˆæ³¢åŠ¨ç¨‹åº¦ï¼‰
        acc_var = np.var(recent_accs)

        # è½¬æ¢ä¸ºç¨³å®šæ€§ç‰¹å¾ï¼šæ–¹å·®è¶Šå°â†’ç¨³å®šæ€§è¶Šé«˜â†’ç‰¹å¾å€¼è¶Šå¤§ï¼ˆ1 / (1 + æ–¹å·®)ï¼‰
        stability = 1.0 / (1.0 + acc_var)

        return stability

    # ==============================================
    # è¾…åŠ©æ–¹æ³•ï¼šè®¡ç®—æ€§èƒ½ç‰¹å¾ï¼ˆæœ¬åœ°è®­ç»ƒæ•ˆæœï¼‰
    # ==============================================
    def _calculate_performance_feature(self, train_metrics: dict) -> float:
        """
        è®¡ç®—æ€§èƒ½ç‰¹å¾ï¼šè¡¡é‡å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒçš„æœ€ç»ˆæ•ˆæœ
        - ä¼˜å…ˆç”¨è®­ç»ƒå‡†ç¡®ç‡ï¼ˆå½’ä¸€åŒ–åˆ°0~1ï¼‰ï¼Œæ— accåˆ™ç”¨lossï¼ˆåå‘å½’ä¸€åŒ–ï¼‰
        """
        if not train_metrics["train_acc"]:
            # æ— å‡†ç¡®ç‡æ•°æ®ï¼šç”¨lossè®¡ç®—ï¼ˆlossè¶Šå°â†’æ€§èƒ½è¶Šå¥½â†’ç‰¹å¾å€¼è¶Šå¤§ï¼‰
            final_loss = train_metrics["train_loss"][-1] if train_metrics["train_loss"] else 10.0
            # lossåå‘å½’ä¸€åŒ–ï¼ˆå‡è®¾æœ€å¤§lossä¸º10ï¼Œå¯æ ¹æ®å®é™…è°ƒæ•´ï¼‰
            performance = 1.0 - (final_loss / 10.0)
            performance = max(0.0, min(1.0, performance))  # é™åˆ¶åœ¨0~1
        else:
            # æœ‰å‡†ç¡®ç‡æ•°æ®ï¼šç›´æ¥å–æœ€ç»ˆaccï¼ˆå·²åœ¨0~1åŒºé—´ï¼‰
            final_acc = train_metrics["train_acc"][-1]
            performance = final_acc

        return performance

    # ==============================================
    # è¾…åŠ©æ–¹æ³•ï¼šç‰¹å¾å½’ä¸€åŒ–ï¼ˆç»Ÿä¸€åˆ°[0,1]åŒºé—´ï¼‰
    # ==============================================
    def _normalize_features(self, features: dict) -> dict:
        """
        ç‰¹å¾å½’ä¸€åŒ–ï¼šå°†æ‰€æœ‰ç‰¹å¾å€¼æ˜ å°„åˆ°[self.feature_norm_range[0], self.feature_norm_range[1]]
        å¤„ç†å¼‚å¸¸å€¼ï¼ˆå¦‚NaNã€Infï¼‰ï¼Œä¿è¯ç‰¹å¾æœ‰æ•ˆæ€§
        """
        normalized = {}
        min_val, max_val = self.feature_norm_range

        for feat_name, feat_val in features.items():
            # å¤„ç†å¼‚å¸¸å€¼
            if np.isnan(feat_val) or np.isinf(feat_val):
                normalized[feat_name] = min_val  # å¼‚å¸¸å€¼é»˜è®¤æœ€å°
                continue

            # å½’ä¸€åŒ–ï¼ˆå·²åœ¨0~1åŒºé—´çš„ç‰¹å¾ç›´æ¥ä¿ç•™ï¼Œä»…å¤„ç†è¾¹ç•Œï¼‰
            normalized_val = max(min_val, min(max_val, feat_val))
            normalized[feat_name] = normalized_val

        return normalized

    # ==============================================
    # å·¥å…·æ–¹æ³•ï¼šæ¨¡å‹å‚æ•°å±•å¹³ï¼ˆä¾¿äºè®¡ç®—ç›¸ä¼¼åº¦/è·ç¦»ï¼‰
    # ==============================================
    def _flatten_params(self, params_list: list) -> np.ndarray:
        """
        å°†æ¨¡å‹å‚æ•°åˆ—è¡¨ï¼ˆæ¯å±‚å‚æ•°ï¼‰å±•å¹³ä¸ºä¸€ç»´numpyæ•°ç»„
        Args:
            params_list: æ¨¡å‹å‚æ•°åˆ—è¡¨ï¼ˆå¦‚model.get_params()è¿”å›çš„åˆ—è¡¨ï¼‰
        Returns:
            å±•å¹³åçš„ä¸€ç»´æ•°ç»„
        """
        flat_params = []
        for param in params_list:
            flat = np.array(param).flatten()
            flat_params.extend(flat)
        return np.array(flat_params, dtype=np.float32)

    # ==============================================
    # è¾…åŠ©æ–¹æ³•ï¼šæ¸…ç©ºå®¢æˆ·ç«¯å†å²ç¼“å­˜ï¼ˆä¾¿äºå¤šæ¬¡å®éªŒï¼‰
    # ==============================================
    def clear_client_history(self, client_id=None) -> None:
        """
        æ¸…ç©ºå®¢æˆ·ç«¯å†å²ç¼“å­˜
        Args:
            client_id: å¯é€‰ï¼ŒæŒ‡å®šå®¢æˆ·ç«¯IDï¼›Noneåˆ™æ¸…ç©ºæ‰€æœ‰å®¢æˆ·ç«¯
        """
        if client_id is None:
            self.client_history = {}
            print("âœ… æ‰€æœ‰å®¢æˆ·ç«¯ALAå†å²ç¼“å­˜å·²æ¸…ç©º")
        else:
            if client_id in self.client_history:
                del self.client_history[client_id]
                print(f"âœ… å®¢æˆ·ç«¯ [{client_id}] ALAå†å²ç¼“å­˜å·²æ¸…ç©º")
            else:
                print(f"âš ï¸  å®¢æˆ·ç«¯ [{client_id}] æ— ALAå†å²ç¼“å­˜ï¼Œæ— éœ€æ¸…ç©º")