# core/dp/adaptive_clipping_dp.py
"""
è‡ªé€‚åº”è£å‰ªå·®åˆ†éšç§ä¼˜åŒ–å™¨ï¼ˆAdaptiveClippingDPï¼‰
æ ¸å¿ƒæ”¹è¿›ï¼š
1. ä¿ç•™æ ¸å¿ƒï¼šã€Œæœ¬è½®-ä¸Šè½®æ¢¯åº¦å·®å€¼ã€è®¡ç®—é€»è¾‘ï¼›
2. æ–°å¢ç²¾ç»†åŒ–å·®å€¼å¤„ç†ï¼šæ¢¯åº¦å·®å€¼å½’ä¸€åŒ– + å·®å€¼åˆ†çº§ï¼ˆä½/ä¸­/é«˜ï¼‰ï¼Œä¸åŒçº§åˆ«å·®å¼‚åŒ–è£å‰ªï¼›
3. æ–°å¢è‡ªèº«æ—¶åºè¾…åŠ©æ ¡å‡†ï¼šåŸºäºå†å²æ¢¯åº¦æ—¶åºç‰¹å¾ï¼ˆæ»‘åŠ¨çª—å£å‡å€¼/æ–¹å·®ï¼‰æ ¡å‡†è£å‰ªé˜ˆå€¼ï¼›
4. æ–°å¢ç¨³å®šæ€§çº¦æŸï¼šé™åˆ¶é˜ˆå€¼å˜åŒ–ç‡ + æ»‘åŠ¨çª—å£å¹³æ»‘ï¼Œé¿å…é˜ˆå€¼å‰§çƒˆæ³¢åŠ¨ï¼›
5. å…¼å®¹å·®åˆ†éšç§æ ¸å¿ƒæµç¨‹ï¼šè£å‰ªï¼ˆClippingï¼‰ + åŠ å™ªï¼ˆAdding Noiseï¼‰ï¼Œä¿è¯DPéšç§é¢„ç®—ã€‚
"""
import numpy as np
import torch
import torch.nn.functional as F
from collections import defaultdict
from copy import deepcopy

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from configs.config_loader import load_config

class AdaptiveClippingDP:
    """
    è‡ªé€‚åº”è£å‰ªå·®åˆ†éšç§ä¼˜åŒ–å™¨
    æ ¸å¿ƒæ–¹æ³•ï¼š
    - adaptive_clip_and_add_noise()ï¼šæ ¸å¿ƒå…¥å£ï¼Œè£å‰ª+åŠ å™ªï¼Œè¿”å›å¸¦DPä¿æŠ¤çš„æ¢¯åº¦ï¼›
    - _calculate_gradient_diff()ï¼šä¿ç•™æ ¸å¿ƒï¼Œè®¡ç®—æœ¬è½®-ä¸Šè½®æ¢¯åº¦å·®å€¼ï¼›
    - _refine_gradient_diff()ï¼šæ–°å¢ï¼Œç²¾ç»†åŒ–å¤„ç†æ¢¯åº¦å·®å€¼ï¼ˆå½’ä¸€åŒ–+åˆ†çº§ï¼‰ï¼›
    - _calibrate_threshold_by_temporal()ï¼šæ–°å¢ï¼Œè‡ªèº«æ—¶åºè¾…åŠ©æ ¡å‡†è£å‰ªé˜ˆå€¼ï¼›
    - _constrain_threshold_stability()ï¼šæ–°å¢ï¼Œç¨³å®šæ€§çº¦æŸè£å‰ªé˜ˆå€¼ï¼›
    - clear_gradient_history()ï¼šæ¸…ç©ºæ¢¯åº¦å†å²ï¼ˆå®éªŒå¤ç”¨ï¼‰ã€‚
    """
    def __init__(self, config=None):
        """
        åˆå§‹åŒ–è‡ªé€‚åº”è£å‰ªDPä¼˜åŒ–å™¨
        Args:
            config: é…ç½®å¯¹è±¡ï¼ˆé»˜è®¤åŠ è½½å…¨å±€é…ç½®ï¼‰
        """
        # 1. åŸºç¡€é…ç½®åˆå§‹åŒ–
        self.config = config if config is not None else load_config()
        self.device = self.config.device
        self.epsilon = self.config.dp.epsilon  # DPéšç§é¢„ç®—Îµ
        self.delta = self.config.dp.delta      # DPéšç§é¢„ç®—Î´ï¼ˆé€šå¸¸è®¾ä¸º1e-5ï¼‰
        self.base_clip_threshold = self.config.dp.base_clip_threshold  # åŸºç¡€è£å‰ªé˜ˆå€¼

        # 2. æ¢¯åº¦å†å²ç¼“å­˜ï¼ˆæ”¯æ’‘å·®å€¼è®¡ç®—ã€æ—¶åºæ ¡å‡†ã€ç¨³å®šæ€§çº¦æŸï¼‰
        # ç»“æ„ï¼š{param_name: {"prev_gradient": ä¸Šè½®æ¢¯åº¦, "diff_history": [å†å²å·®å€¼åˆ—è¡¨], "threshold_history": [å†å²é˜ˆå€¼åˆ—è¡¨]}}
        self.gradient_history = defaultdict(dict)
        # æ»‘åŠ¨çª—å£é…ç½®ï¼ˆæ—¶åºæ ¡å‡†/ç¨³å®šæ€§çº¦æŸç”¨ï¼‰
        self.sliding_window_size = self.config.dp.sliding_window_size  # æ»‘åŠ¨çª—å£å¤§å°ï¼ˆå¦‚5è½®ï¼‰
        self.threshold_change_rate = self.config.dp.threshold_change_rate  # é˜ˆå€¼æœ€å¤§å˜åŒ–ç‡ï¼ˆå¦‚0.2=Â±20%ï¼‰

        # 3. ç²¾ç»†åŒ–å·®å€¼å¤„ç†é…ç½®
        self.diff_normalize_range = (0.0, 1.0)  # å·®å€¼å½’ä¸€åŒ–èŒƒå›´
        self.diff_levels = {  # å·®å€¼åˆ†çº§é˜ˆå€¼ï¼ˆ0~1ï¼Œå¯¹åº”å½’ä¸€åŒ–åçš„å€¼ï¼‰
            "low": (0.0, 0.3),    # ä½å·®å€¼ï¼šå°å¹…æ³¢åŠ¨ï¼Œå®½æ¾è£å‰ª
            "medium": (0.3, 0.7), # ä¸­å·®å€¼ï¼šæ­£å¸¸æ³¢åŠ¨ï¼Œæ ‡å‡†è£å‰ª
            "high": (0.7, 1.0)    # é«˜å·®å€¼ï¼šå¤§å¹…æ³¢åŠ¨ï¼Œä¸¥æ ¼è£å‰ª
        }
        self.level_clip_coeff = {  # ä¸åŒçº§åˆ«è£å‰ªç³»æ•°ï¼ˆä¹˜ä»¥åŸºç¡€é˜ˆå€¼ï¼‰
            "low": 1.2,    # ä½å·®å€¼ï¼šé˜ˆå€¼Ã—1.2ï¼ˆæ›´å®½æ¾ï¼‰
            "medium": 1.0, # ä¸­å·®å€¼ï¼šé˜ˆå€¼Ã—1.0ï¼ˆæ ‡å‡†ï¼‰
            "high": 0.8    # é«˜å·®å€¼ï¼šé˜ˆå€¼Ã—0.8ï¼ˆæ›´ä¸¥æ ¼ï¼‰
        }

        # 4. DPå™ªå£°é…ç½®
        self.noise_scale = self.base_clip_threshold * np.sqrt(2 * np.log(1.25 / self.delta)) / self.epsilon  # å™ªå£°ç¼©æ”¾å› å­
        self.epsilon_min = 1e-6  # é¿å…é™¤é›¶çš„æå°å€¼

        print(f"âœ… è‡ªé€‚åº”è£å‰ªDPä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Œ DPéšç§é¢„ç®—ï¼šÎµ={self.epsilon} | Î´={self.delta} | åŸºç¡€è£å‰ªé˜ˆå€¼={self.base_clip_threshold}")
        print(f"ğŸ“Œ æ—¶åº/ç¨³å®šæ€§é…ç½®ï¼šæ»‘åŠ¨çª—å£={self.sliding_window_size} | é˜ˆå€¼å˜åŒ–ç‡={self.threshold_change_rate}")
        print(f"ğŸ“Œ å·®å€¼åˆ†çº§ï¼šä½({self.diff_levels['low']}) | ä¸­({self.diff_levels['medium']}) | é«˜({self.diff_levels['high']})")

    # ==============================================
    # æ ¸å¿ƒå…¥å£ï¼šè‡ªé€‚åº”è£å‰ª+æ·»åŠ DPå™ªå£°ï¼ˆå®¢æˆ·ç«¯è°ƒç”¨ï¼‰
    # ==============================================
    def adaptive_clip_and_add_noise(self, model, current_gradient_dict: dict) -> dict:
        """
        æ ¸å¿ƒå…¥å£ï¼šå¯¹æ¨¡å‹æ¢¯åº¦åšè‡ªé€‚åº”è£å‰ª + æ·»åŠ DPå™ªå£°ï¼Œè¿”å›å¸¦éšç§ä¿æŠ¤çš„æ¢¯åº¦
        Args:
            model: å®¢æˆ·ç«¯æœ¬åœ°æ¨¡å‹å®ä¾‹ï¼ˆç”¨äºè·å–å‚æ•°åï¼‰
            current_gradient_dict: å½“å‰è½®æ¬¡æ¢¯åº¦å­—å…¸ {param_name: gradient_tensor}
        Returns:
            protected_gradient_dict: å¸¦DPä¿æŠ¤çš„æ¢¯åº¦å­—å…¸ {param_name: protected_gradient}
        """
        protected_gradient_dict = {}

        for param_name, current_grad in current_gradient_dict.items():
            # æ­¥éª¤1ï¼šè®¡ç®—æœ¬è½®-ä¸Šè½®æ¢¯åº¦å·®å€¼ï¼ˆä¿ç•™æ ¸å¿ƒé€»è¾‘ï¼‰
            grad_diff = self._calculate_gradient_diff(param_name, current_grad)

            # æ­¥éª¤2ï¼šç²¾ç»†åŒ–å¤„ç†æ¢¯åº¦å·®å€¼ï¼ˆå½’ä¸€åŒ–+åˆ†çº§ï¼‰
            normalized_diff, diff_level = self._refine_gradient_diff(param_name, grad_diff)

            # æ­¥éª¤3ï¼šåŸºäºæ—¶åºç‰¹å¾æ ¡å‡†è£å‰ªé˜ˆå€¼
            calibrated_threshold = self._calibrate_threshold_by_temporal(param_name, diff_level)

            # æ­¥éª¤4ï¼šç¨³å®šæ€§çº¦æŸè£å‰ªé˜ˆå€¼ï¼ˆé¿å…å‰§çƒˆæ³¢åŠ¨ï¼‰
            stable_threshold = self._constrain_threshold_stability(param_name, calibrated_threshold)

            # æ­¥éª¤5ï¼šè‡ªé€‚åº”è£å‰ªæ¢¯åº¦
            clipped_gradient = self._clip_gradient(current_grad, stable_threshold)

            # æ­¥éª¤6ï¼šæ·»åŠ DPå™ªå£°
            protected_gradient = self._add_dp_noise(clipped_gradient, stable_threshold)

            # ä¿å­˜æœ¬è½®æ¢¯åº¦/é˜ˆå€¼åˆ°å†å²ï¼ˆä¾›ä¸‹è½®ä½¿ç”¨ï¼‰
            self.gradient_history[param_name]["prev_gradient"] = deepcopy(current_grad.cpu())
            if "threshold_history" not in self.gradient_history[param_name]:
                self.gradient_history[param_name]["threshold_history"] = []
            self.gradient_history[param_name]["threshold_history"].append(stable_threshold)
            # ä¿å­˜å·®å€¼åˆ°å†å²ï¼ˆä¾›æ—¶åºæ ¡å‡†/ç¨³å®šæ€§çº¦æŸä½¿ç”¨ï¼‰
            if "diff_history" not in self.gradient_history[param_name]:
                self.gradient_history[param_name]["diff_history"] = []
            self.gradient_history[param_name]["diff_history"].append(normalized_diff)
            # æˆªæ–­å†å²åˆ—è¡¨ï¼ˆä»…ä¿ç•™æ»‘åŠ¨çª—å£å†…çš„æ•°æ®ï¼‰
            self._truncate_sliding_window(param_name)

            protected_gradient_dict[param_name] = protected_gradient.to(self.device)

            # æ‰“å°å•å‚æ•°å¤„ç†ç»“æœï¼ˆå‰3ä¸ªå‚æ•°ï¼Œè¾…åŠ©è°ƒè¯•ï¼‰
            if len(protected_gradient_dict) <= 3:
                print(f"\nğŸ“Œ å‚æ•° [{param_name}] DPå¤„ç†ç»“æœï¼š")
                print(f"   æ¢¯åº¦å·®å€¼ï¼ˆå½’ä¸€åŒ–ï¼‰ï¼š{normalized_diff:.4f} | å·®å€¼çº§åˆ«ï¼š{diff_level}")
                print(f"   æ ¡å‡†åé˜ˆå€¼ï¼š{calibrated_threshold:.4f} | ç¨³å®šåé˜ˆå€¼ï¼š{stable_threshold:.4f}")
                print(f"   å™ªå£°ç¼©æ”¾å› å­ï¼š{self.noise_scale:.4f}")

        return protected_gradient_dict

    # ==============================================
    # ä¿ç•™æ ¸å¿ƒï¼šè®¡ç®—æœ¬è½®-ä¸Šè½®æ¢¯åº¦å·®å€¼
    # ==============================================
    def _calculate_gradient_diff(self, param_name: str, current_grad: torch.Tensor) -> float:
        """
        ä¿ç•™æ ¸å¿ƒé€»è¾‘ï¼šè®¡ç®—æœ¬è½®æ¢¯åº¦ä¸ä¸Šè½®æ¢¯åº¦çš„L2å·®å€¼ï¼ˆæ ‡é‡ï¼‰
        Args:
            param_name: å‚æ•°åï¼ˆå¦‚conv1.weightï¼‰
            current_grad: å½“å‰è½®æ¬¡æ¢¯åº¦å¼ é‡
        Returns:
            grad_diff: æ¢¯åº¦å·®å€¼ï¼ˆæ ‡é‡ï¼ŒL2è·ç¦»ï¼‰
        """
        # é¦–æ¬¡è®¡ç®—ï¼šæ— ä¸Šè½®æ¢¯åº¦ï¼Œå·®å€¼è®¾ä¸º0
        if "prev_gradient" not in self.gradient_history[param_name] or self.gradient_history[param_name]["prev_gradient"] is None:
            self.gradient_history[param_name]["prev_gradient"] = deepcopy(current_grad.cpu())
            return 0.0

        # è®¡ç®—L2å·®å€¼ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼Œå®Œå…¨ä¿ç•™ï¼‰
        prev_grad = self.gradient_history[param_name]["prev_gradient"].to(self.device)
        grad_diff = torch.norm(current_grad - prev_grad, p=2).item()  # L2èŒƒæ•°ï¼ˆå·®å€¼å¤§å°ï¼‰

        return grad_diff

    # ==============================================
    # æ–°å¢ï¼šç²¾ç»†åŒ–å¤„ç†æ¢¯åº¦å·®å€¼ï¼ˆå½’ä¸€åŒ–+åˆ†çº§ï¼‰
    # ==============================================
    def _refine_gradient_diff(self, param_name: str, grad_diff: float) -> tuple[float, str]:
        """
        æ–°å¢ï¼šç²¾ç»†åŒ–å¤„ç†æ¢¯åº¦å·®å€¼ â†’ å½’ä¸€åŒ– + åˆ†çº§
        Args:
            param_name: å‚æ•°å
            grad_diff: åŸå§‹æ¢¯åº¦å·®å€¼
        Returns:
            normalized_diff: å½’ä¸€åŒ–åçš„å·®å€¼ï¼ˆ0~1ï¼‰
            diff_level: å·®å€¼çº§åˆ«ï¼ˆlow/medium/highï¼‰
        """
        # 1. å·®å€¼å½’ä¸€åŒ–ï¼ˆåŸºäºæ»‘åŠ¨çª—å£å†…çš„å†å²å·®å€¼ï¼‰
        diff_history = self.gradient_history[param_name].get("diff_history", [])
        if not diff_history:
            # æ— å†å²å·®å€¼ï¼šç”¨åŸºç¡€é˜ˆå€¼å½’ä¸€åŒ–
            normalized_diff = min(grad_diff / (self.base_clip_threshold + self.epsilon_min), 1.0)
        else:
            # æœ‰å†å²å·®å€¼ï¼šåŸºäºæ»‘åŠ¨çª—å£å†…çš„æœ€å¤§/æœ€å°å€¼å½’ä¸€åŒ–
            window_diff = diff_history[-self.sliding_window_size:] if len(diff_history) >= self.sliding_window_size else diff_history
            diff_min = min(window_diff)
            diff_max = max(window_diff)
            if diff_max - diff_min < self.epsilon_min:
                normalized_diff = self.diff_normalize_range[0]
            else:
                norm_min, norm_max = self.diff_normalize_range
                normalized_diff = norm_min + (grad_diff - diff_min) * (norm_max - norm_min) / (diff_max - diff_min)
            # é™åˆ¶åœ¨0~1åŒºé—´
            normalized_diff = max(self.diff_normalize_range[0], min(self.diff_normalize_range[1], normalized_diff))

        # 2. å·®å€¼åˆ†çº§
        diff_level = "medium"  # é»˜è®¤ä¸­çº§åˆ«
        if self.diff_levels["low"][0] <= normalized_diff < self.diff_levels["low"][1]:
            diff_level = "low"
        elif self.diff_levels["high"][0] <= normalized_diff <= self.diff_levels["high"][1]:
            diff_level = "high"

        return normalized_diff, diff_level

    # ==============================================
    # æ–°å¢ï¼šè‡ªèº«æ—¶åºè¾…åŠ©æ ¡å‡†è£å‰ªé˜ˆå€¼
    # ==============================================
    def _calibrate_threshold_by_temporal(self, param_name: str, diff_level: str) -> float:
        """
        æ–°å¢ï¼šåŸºäºå†å²æ¢¯åº¦æ—¶åºç‰¹å¾ï¼ˆæ»‘åŠ¨çª—å£å‡å€¼/æ–¹å·®ï¼‰æ ¡å‡†è£å‰ªé˜ˆå€¼
        é€»è¾‘ï¼š
        - æ»‘åŠ¨çª—å£å†…å·®å€¼å‡å€¼é«˜ â†’ æ¢¯åº¦æ³¢åŠ¨å¤§ â†’ é™ä½é˜ˆå€¼ï¼›
        - æ»‘åŠ¨çª—å£å†…å·®å€¼æ–¹å·®é«˜ â†’ æ¢¯åº¦ä¸ç¨³å®š â†’ é™ä½é˜ˆå€¼ï¼›
        - ç»“åˆå·®å€¼çº§åˆ«ï¼Œåº”ç”¨åˆ†çº§è£å‰ªç³»æ•°ã€‚
        Args:
            param_name: å‚æ•°å
            diff_level: å·®å€¼çº§åˆ«ï¼ˆlow/medium/highï¼‰
        Returns:
            calibrated_threshold: æ—¶åºæ ¡å‡†åçš„è£å‰ªé˜ˆå€¼
        """
        # 1. åŸºç¡€åˆ†çº§é˜ˆå€¼ï¼ˆä¹˜ä»¥çº§åˆ«ç³»æ•°ï¼‰
        level_coeff = self.level_clip_coeff[diff_level]
        level_threshold = self.base_clip_threshold * level_coeff

        # 2. æ—¶åºç‰¹å¾æ ¡å‡†ï¼ˆåŸºäºæ»‘åŠ¨çª—å£å†…çš„å·®å€¼ç»Ÿè®¡ï¼‰
        diff_history = self.gradient_history[param_name].get("diff_history", [])
        if len(diff_history) < 2:
            # å†å²æ•°æ®ä¸è¶³ï¼šç›´æ¥è¿”å›åˆ†çº§é˜ˆå€¼
            return level_threshold

        # å–æ»‘åŠ¨çª—å£å†…çš„å·®å€¼
        window_diff = diff_history[-self.sliding_window_size:] if len(diff_history) >= self.sliding_window_size else diff_history
        diff_mean = np.mean(window_diff)  # å·®å€¼å‡å€¼ï¼ˆæ³¢åŠ¨å¤§å°ï¼‰
        diff_var = np.var(window_diff)    # å·®å€¼æ–¹å·®ï¼ˆç¨³å®šæ€§ï¼‰

        # æ ¡å‡†ç³»æ•°ï¼šå‡å€¼/æ–¹å·®è¶Šé«˜ï¼Œç³»æ•°è¶Šå°ï¼ˆé˜ˆå€¼è¶Šä½ï¼‰
        mean_coeff = 1.0 - min(diff_mean * 0.5, 0.3)  # å‡å€¼æ ¡å‡†ç³»æ•°ï¼ˆæœ€å¤šé™30%ï¼‰
        var_coeff = 1.0 - min(diff_var * 0.5, 0.2)    # æ–¹å·®æ ¡å‡†ç³»æ•°ï¼ˆæœ€å¤šé™20%ï¼‰
        temporal_coeff = mean_coeff * var_coeff

        # æœ€ç»ˆæ ¡å‡†é˜ˆå€¼
        calibrated_threshold = level_threshold * temporal_coeff
        # ç¡®ä¿é˜ˆå€¼ä¸ºæ­£
        calibrated_threshold = max(calibrated_threshold, self.epsilon_min)

        return calibrated_threshold

    # ==============================================
    # æ–°å¢ï¼šç¨³å®šæ€§çº¦æŸè£å‰ªé˜ˆå€¼
    # ==============================================
    def _constrain_threshold_stability(self, param_name: str, calibrated_threshold: float) -> float:
        """
        æ–°å¢ï¼šç¨³å®šæ€§çº¦æŸ â†’ é™åˆ¶é˜ˆå€¼å˜åŒ–ç‡ + æ»‘åŠ¨çª—å£å¹³æ»‘ï¼Œé¿å…é˜ˆå€¼å‰§çƒˆæ³¢åŠ¨
        Args:
            param_name: å‚æ•°å
            calibrated_threshold: æ—¶åºæ ¡å‡†åçš„é˜ˆå€¼
        Returns:
            stable_threshold: ç¨³å®šæ€§çº¦æŸåçš„é˜ˆå€¼
        """
        threshold_history = self.gradient_history[param_name].get("threshold_history", [])
        if not threshold_history:
            # æ— å†å²é˜ˆå€¼ï¼šç›´æ¥è¿”å›æ ¡å‡†é˜ˆå€¼
            return calibrated_threshold

        # 1. é™åˆ¶é˜ˆå€¼å˜åŒ–ç‡ï¼ˆä¸è¶…è¿‡Â±threshold_change_rateï¼‰
        prev_threshold = threshold_history[-1]  # ä¸Šè½®é˜ˆå€¼
        max_increase = prev_threshold * (1 + self.threshold_change_rate)
        max_decrease = prev_threshold * (1 - self.threshold_change_rate)
        constrained_threshold = max(max_decrease, min(max_increase, calibrated_threshold))

        # 2. æ»‘åŠ¨çª—å£å¹³æ»‘ï¼ˆè¿›ä¸€æ­¥é™ä½æ³¢åŠ¨ï¼‰
        window_threshold = threshold_history[-self.sliding_window_size:] if len(threshold_history) >= self.sliding_window_size else threshold_history
        window_mean = np.mean(window_threshold)
        stable_threshold = 0.7 * constrained_threshold + 0.3 * window_mean  # 70%å½“å‰å€¼ + 30%çª—å£å‡å€¼

        # ç¡®ä¿é˜ˆå€¼ä¸ºæ­£
        stable_threshold = max(stable_threshold, self.epsilon_min)

        return stable_threshold

    # ==============================================
    # è¾…åŠ©æ–¹æ³•1ï¼šæ¢¯åº¦è£å‰ªï¼ˆL2è£å‰ªï¼‰
    # ==============================================
    def _clip_gradient(self, gradient: torch.Tensor, threshold: float) -> torch.Tensor:
        """
        æ¢¯åº¦è£å‰ªï¼šL2èŒƒæ•°è£å‰ªï¼Œç¡®ä¿æ¢¯åº¦çš„L2èŒƒæ•°ä¸è¶…è¿‡é˜ˆå€¼
        """
        grad_norm = torch.norm(gradient, p=2)
        if grad_norm > threshold:
            clipped_gradient = gradient * (threshold / (grad_norm + self.epsilon_min))
        else:
            clipped_gradient = gradient
        return clipped_gradient

    # ==============================================
    # è¾…åŠ©æ–¹æ³•2ï¼šæ·»åŠ DPå™ªå£°ï¼ˆé«˜æ–¯å™ªå£°ï¼‰
    # ==============================================
    def _add_dp_noise(self, gradient: torch.Tensor, threshold: float) -> torch.Tensor:
        """
        æ·»åŠ DPé«˜æ–¯å™ªå£°ï¼šå™ªå£°å°ºåº¦ä¸è£å‰ªé˜ˆå€¼æ­£ç›¸å…³
        """
        # åŠ¨æ€è°ƒæ•´å™ªå£°å°ºåº¦ï¼ˆä¸å½“å‰é˜ˆå€¼åŒ¹é…ï¼‰
        dynamic_noise_scale = threshold * np.sqrt(2 * np.log(1.25 / self.delta)) / (self.epsilon + self.epsilon_min)
        # ç”Ÿæˆé«˜æ–¯å™ªå£°ï¼ˆä¸æ¢¯åº¦åŒå½¢çŠ¶ã€åŒè®¾å¤‡ï¼‰
        noise = torch.normal(0, dynamic_noise_scale, size=gradient.shape, device=self.device)
        # æ·»åŠ å™ªå£°
        noisy_gradient = gradient + noise
        return noisy_gradient

    # ==============================================
    # è¾…åŠ©æ–¹æ³•3ï¼šæˆªæ–­æ»‘åŠ¨çª—å£ï¼ˆé¿å…å†å²æ•°æ®è¿‡å¤šï¼‰
    # ==============================================
    def _truncate_sliding_window(self, param_name: str) -> None:
        """
        æˆªæ–­æ¢¯åº¦å·®å€¼/é˜ˆå€¼çš„å†å²åˆ—è¡¨ï¼Œä»…ä¿ç•™æ»‘åŠ¨çª—å£å†…çš„æ•°æ®
        """
        if "diff_history" in self.gradient_history[param_name]:
            self.gradient_history[param_name]["diff_history"] = self.gradient_history[param_name]["diff_history"][-self.sliding_window_size:]
        if "threshold_history" in self.gradient_history[param_name]:
            self.gradient_history[param_name]["threshold_history"] = self.gradient_history[param_name]["threshold_history"][-self.sliding_window_size:]

    # ==============================================
    # è¾…åŠ©æ–¹æ³•ï¼šæ¸…ç©ºæ¢¯åº¦å†å²ï¼ˆå®éªŒå¤ç”¨ï¼‰
    # ==============================================
    def clear_gradient_history(self) -> None:
        """
        æ¸…ç©ºæ‰€æœ‰æ¢¯åº¦å†å²ç¼“å­˜ï¼ˆç”¨äºå¤šæ¬¡å®éªŒï¼Œé¿å…å†å²æ•°æ®å¹²æ‰°ï¼‰
        """
        self.gradient_history = defaultdict(dict)
        print("âœ… æ¢¯åº¦å†å²ç¼“å­˜å·²æ¸…ç©ºï¼ŒDPä¼˜åŒ–å™¨å¯é‡æ–°ä½¿ç”¨")