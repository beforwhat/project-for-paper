# core/federated/client.py
"""
è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯åŸºç±»ï¼ˆBaseClientï¼‰
æ ¸å¿ƒèŒè´£ï¼š
1.  å°è£…å®¢æˆ·ç«¯é€šç”¨æµç¨‹ï¼šä¸‹è½½å…¨å±€æ¨¡å‹ â†’ æœ¬åœ°è®­ç»ƒ â†’ æå–è´¡çŒ®åº¦ç‰¹å¾ â†’ ä¸Šä¼ æœ¬åœ°ç»“æœ
2.  å…¼å®¹ç°æœ‰æ ¸å¿ƒæ¨¡å—ï¼šALAï¼ˆè‡ªé€‚åº”æ›´æ–°ï¼‰ã€ä¼ªæ ‡ç­¾ï¼ˆæ•°æ®å¢å¼ºï¼‰ã€DPï¼ˆå·®åˆ†éšç§ï¼‰ã€Shapleyï¼ˆSAè´¡çŒ®åº¦ï¼‰
3.  ä½œä¸ºåŸºç±»é¢„ç•™æ‰©å±•æ¥å£ï¼Œæ–¹ä¾¿åç»­å­ç±»å®šåˆ¶ï¼ˆå¦‚åˆ†ç±»/å›å½’ä»»åŠ¡å®¢æˆ·ç«¯ï¼‰
4.  æ— ä¿®æ”¹æ ¸å¿ƒé€šä¿¡é€»è¾‘ï¼Œä»…åµŒå…¥è¾…åŠ©æ¨¡å—æ”¯æ’‘ï¼Œä¿æŒé€šç”¨æ€§
"""
import os
import numpy as np
import torch
import torch.optim as optim
from tqdm import tqdm

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥ï¼ˆå…¼å®¹coreä¸‹çš„å…¶ä»–æ ¸å¿ƒæ¨¡å—ï¼‰
from configs.config_loader import load_config
from models import get_model, BaseModel
from core.ala.ala_optimizer import ALAOptimizer
from core.pseudo_label.pseudo_label import PseudoLabelGenerator
from core.dp.adaptive_clipping_dp import AdaptiveClippingDP

class BaseClient:
    """
    è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯åŸºç±»
    æ ¸å¿ƒæµç¨‹ï¼šdownload_global_model() â†’ local_train() â†’ extract_client_contribution_features() â†’ upload_local_results()
    """
    def __init__(self, client_id: int, config=None, model=None, dataset=None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        Args:
            client_id: å®¢æˆ·ç«¯å”¯ä¸€æ ‡è¯†ï¼ˆä¸å¯é‡å¤ï¼‰
            config: é…ç½®å¯¹è±¡ï¼ˆé»˜è®¤åŠ è½½å…¨å±€é…ç½®ï¼‰
            model: æœ¬åœ°æ¨¡å‹å®ä¾‹ï¼ˆé»˜è®¤ä»modelsè·å–ï¼Œä¸å…¨å±€æ¨¡å‹ç»“æ„ä¸€è‡´ï¼‰
            dataset: å®¢æˆ·ç«¯æœ¬åœ°æ•°æ®é›†ï¼ˆå·²åˆ’åˆ†å¥½çš„å®¢æˆ·ç«¯ç§æœ‰æ•°æ®ï¼‰
        """
        # 1. åŸºç¡€å±æ€§åˆå§‹åŒ–
        self.client_id = client_id
        self.config = config if config is not None else load_config()
        self.device = self.config.device
        self.local_epochs = self.config.fed.num_local_epochs
        self.local_lr = self.config.fed.local_lr
        self.local_momentum = self.config.fed.local_momentum

        # 2. æ ¸å¿ƒå¯¹è±¡åˆå§‹åŒ–ï¼ˆæ¨¡å‹ã€æ•°æ®é›†ï¼‰
        self.local_model = model if model is not None else self._init_local_model()
        self.local_dataset = dataset
        self.local_dataloader = self._init_local_dataloader() if self.local_dataset else None

        # 3. è¾…åŠ©æ¨¡å—åˆå§‹åŒ–ï¼ˆå…¼å®¹ç°æœ‰æ ¸å¿ƒæ¨¡å—ï¼ŒæŒ‰éœ€å¯ç”¨ï¼‰
        self.ala_optimizer = ALAOptimizer(config=self.config)  # ALAè‡ªé€‚åº”æ›´æ–° + ç‰¹å¾æå–
        self.pseudo_label_generator = PseudoLabelGenerator(config=self.config)  # é«˜ç½®ä¿¡ä¼ªæ ‡ç­¾ç”Ÿæˆ
        self.adaptive_dp = AdaptiveClippingDP(config=self.config)  # DPè‡ªé€‚åº”è£å‰ªï¼ˆå¸¦ç²¾ç»†åŒ–ä¼˜åŒ–ï¼‰

        # 4. è®­ç»ƒ/è¯„ä¼°æŒ‡æ ‡è®°å½•ï¼ˆç”¨äºåç»­è´¡çŒ®åº¦è®¡ç®—ã€æ¨¡å‹åˆ†æï¼‰
        self.train_metrics = {
            "train_loss": [],
            "train_acc": [],
            "local_sample_num": len(self.local_dataset.target_dataset) if self.local_dataset else 0
        }
        self.client_features = {}  # å®¢æˆ·ç«¯è´¡çŒ®åº¦ç‰¹å¾ï¼ˆALAæå–ï¼šåå·®ã€ç¨³å®šæ€§ã€æ€§èƒ½ï¼‰
        self.trained_local_params = None  # æœ¬åœ°è®­ç»ƒåçš„æ¨¡å‹å‚æ•°ï¼ˆç”¨äºä¸Šä¼ æœåŠ¡ç«¯ï¼‰

    def _init_local_model(self) -> BaseModel:
        """
        åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹ï¼ˆä¸å…¨å±€æ¨¡å‹ç»“æ„ä¸€è‡´ï¼Œå¤ç”¨modelsä¸‹çš„åŸºç¡€æ¨¡å‹ï¼‰
        Returns:
            åˆå§‹åŒ–å®Œæˆçš„æœ¬åœ°æ¨¡å‹å®ä¾‹ï¼ˆå·²ç§»è‡³æŒ‡å®šè®¾å¤‡ï¼‰
        """
        local_model = get_model(config=self.config)
        local_model = local_model.to(self.device)
        print(f"âœ… å®¢æˆ·ç«¯ [{self.client_id}] æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆè®¾å¤‡ï¼š{self.device}ï¼‰")
        return local_model

    def _init_local_dataloader(self):
        """åˆå§‹åŒ–æœ¬åœ°æ•°æ®é›†DataLoaderï¼ˆå¤ç”¨æ•°æ®é›†æ¨¡å—çš„åŠ è½½é€»è¾‘ï¼‰"""
        if not self.local_dataset:
            raise ValueError(f"å®¢æˆ·ç«¯ [{self.client_id}] æœªä¼ å…¥æœ‰æ•ˆæ•°æ®é›†ï¼Œæ— æ³•åˆå§‹åŒ–DataLoader")
        return self.local_dataset.get_dataloader()

    # ==============================================
    # æ ¸å¿ƒæ–¹æ³•1ï¼šä¸‹è½½å…¨å±€æ¨¡å‹ï¼ˆä»æœåŠ¡ç«¯è·å–å…¨å±€å‚æ•°ï¼Œæ›´æ–°æœ¬åœ°æ¨¡å‹ï¼‰
    # ==============================================
    def download_global_model(self, global_model_params: list) -> None:
        """
        ä¸‹è½½æœåŠ¡ç«¯å…¨å±€æ¨¡å‹å‚æ•°ï¼Œæ›´æ–°æœ¬åœ°æ¨¡å‹
        Args:
            global_model_params: æœåŠ¡ç«¯ä¸‹å‘çš„å…¨å±€æ¨¡å‹å‚æ•°ï¼ˆä¸æœ¬åœ°æ¨¡å‹ç»“æ„ä¸€è‡´çš„numpyåˆ—è¡¨ï¼‰
        """
        if not global_model_params:
            raise ValueError("å…¨å±€æ¨¡å‹å‚æ•°ä¸ºç©ºï¼Œæ— æ³•æ›´æ–°æœ¬åœ°æ¨¡å‹")
        
        # åŠ è½½å…¨å±€å‚æ•°åˆ°æœ¬åœ°æ¨¡å‹
        self.local_model.set_params(global_model_params)
        print(f"âœ… å®¢æˆ·ç«¯ [{self.client_id}] å·²æˆåŠŸä¸‹è½½å¹¶åŠ è½½å…¨å±€æ¨¡å‹å‚æ•°")

    # ==============================================
    # æ ¸å¿ƒæ–¹æ³•2ï¼šæœ¬åœ°è®­ç»ƒï¼ˆæ•´åˆALAã€ä¼ªæ ‡ç­¾ã€DPï¼Œæ— ä¿®æ”¹æ ¸å¿ƒè®­ç»ƒæµç¨‹ï¼‰
    # ==============================================
    def local_train(self) -> None:
        """
        å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼ˆæ ¸å¿ƒæµç¨‹ï¼Œå…¼å®¹æ‰€æœ‰è¾…åŠ©æ¨¡å—ï¼Œä¿æŒåŸºç±»é€šç”¨æ€§ï¼‰
        æµç¨‹ï¼šALAè‡ªé€‚åº”åˆå§‹åŒ– â†’ ç”Ÿæˆä¼ªæ ‡ç­¾ â†’ å¸¦DPè£å‰ªçš„æœ¬åœ°è®­ç»ƒ â†’ ALAç‰¹å¾æå–
        """
        if not self.local_dataloader:
            raise RuntimeError(f"å®¢æˆ·ç«¯ [{self.client_id}] æ— æœ‰æ•ˆæ•°æ®åŠ è½½å™¨ï¼Œæ— æ³•è¿›è¡Œæœ¬åœ°è®­ç»ƒ")
        
        # 1. åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ˆå¸¦DPè‡ªé€‚åº”è£å‰ªçš„æ¢¯åº¦ä¼˜åŒ–ï¼‰
        optimizer = optim.SGD(
            self.local_model.parameters(),
            lr=self.local_lr,
            momentum=self.local_momentum
        )

        # 2. å‰ç½®å‡†å¤‡ï¼šALAè‡ªé€‚åº”æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–ï¼ˆç¼“è§£å®¢æˆ·ç«¯å¼‚è´¨æ€§ï¼‰
        self.local_model = self.ala_optimizer.ala_adaptive_update(
            client_id=self.client_id,
            local_model=self.local_model,
            global_model_params=self.local_model.get_params()  # åˆå§‹ä¸ºå…¨å±€å‚æ•°
        )

        # 3. ç”Ÿæˆé«˜ç½®ä¿¡åº¦ä¼ªæ ‡ç­¾ï¼ˆæå‡æœ¬åœ°æ•°æ®åˆ©ç”¨ç‡ï¼ŒåŠç›‘ç£è®­ç»ƒï¼‰
        pseudo_images, pseudo_labels = self.pseudo_label_generator.generate_high_conf_pseudo_labels(
            model=self.local_model,
            dataloader=self.local_dataloader
        )
        has_pseudo_data = pseudo_images is not None and pseudo_labels is not None

        # 4. æœ¬åœ°è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒï¼šå¸¦DPè£å‰ªã€ALAè‡ªé€‚åº”è°ƒæ•´ï¼‰
        self.local_model.train()
        print(f"ğŸš€ å®¢æˆ·ç«¯ [{self.client_id}] å¼€å§‹æœ¬åœ°è®­ç»ƒï¼ˆ{self.local_epochs} è½®ï¼‰")
        for epoch in tqdm(range(self.local_epochs), desc=f"å®¢æˆ·ç«¯ [{self.client_id}] æœ¬åœ°è®­ç»ƒ"):
            epoch_loss = 0.0
            epoch_correct = 0
            epoch_total = 0

            for batch_idx, (images, labels) in enumerate(self.local_dataloader):
                images, labels = images.to(self.device), labels.to(self.device)

                # ï¼ˆ1ï¼‰å‰å‘ä¼ æ’­ï¼šçœŸå®æ ‡ç­¾æ•°æ®è®­ç»ƒ
                optimizer.zero_grad()
                outputs = self.local_model(images)
                loss = self.local_model.loss_fn(outputs, labels)

                # ï¼ˆ2ï¼‰ä¼ªæ ‡ç­¾è”åˆè®­ç»ƒï¼ˆæŒ‰éœ€å¯ç”¨ï¼ŒåŠ æƒèåˆæŸå¤±ï¼‰
                if has_pseudo_data and batch_idx % int(1/self.config.fed.pseudo_batch_ratio) == 0:
                    pseudo_batch = self.pseudo_label_generator.get_pseudo_batch(
                        pseudo_images=pseudo_images,
                        pseudo_labels=pseudo_labels,
                        batch_size=32
                    )
                    if pseudo_batch:
                        pseudo_imgs, pseudo_labs = pseudo_batch
                        pseudo_imgs, pseudo_labs = pseudo_imgs.to(self.device), pseudo_labs.to(self.device)
                        pseudo_outputs = self.local_model(pseudo_imgs)
                        pseudo_loss = self.local_model.loss_fn(pseudo_outputs, pseudo_labs)
                        loss = 0.7 * loss + 0.3 * pseudo_loss  # çœŸå®æ ‡ç­¾æƒé‡ä¼˜å…ˆ

                # ï¼ˆ3ï¼‰åå‘ä¼ æ’­ï¼šå¸¦DPè‡ªé€‚åº”è£å‰ªï¼ˆç²¾ç»†åŒ–æ¢¯åº¦å¤„ç†ï¼Œä¿è¯éšç§ï¼‰
                loss.backward()
                # DPè‡ªé€‚åº”è£å‰ªï¼ˆä¼˜åŒ–åï¼šå½’ä¸€åŒ–+åˆ†çº§+æ—¶åºæ ¡å‡†+ç¨³å®šæ€§çº¦æŸï¼‰
                self.adaptive_dp.clip_gradient(self.local_model.parameters())
                optimizer.step()

                # ï¼ˆ4ï¼‰è®°å½•æ‰¹æ¬¡æŒ‡æ ‡
                epoch_loss += loss.item() * images.size(0)
                _, predicted = torch.max(outputs.data, 1)
                epoch_correct += (predicted == labels).sum().item()
                epoch_total += images.size(0)

            # 5. è®°å½•è½®æ¬¡æŒ‡æ ‡
            avg_epoch_loss = epoch_loss / epoch_total
            avg_epoch_acc = epoch_correct / epoch_total
            self.train_metrics["train_loss"].append(avg_epoch_loss)
            self.train_metrics["train_acc"].append(avg_epoch_acc)

            # 6. ALAè‡ªé€‚åº”è°ƒæ•´ï¼ˆæ¯è½®è®­ç»ƒåæ›´æ–°ï¼Œæå‡æ¨¡å‹ç¨³å®šæ€§ï¼‰
            self.local_model = self.ala_optimizer.ala_adaptive_update(
                client_id=self.client_id,
                local_model=self.local_model,
                epoch=epoch
            )

        # 7. è®­ç»ƒå®Œæˆåï¼šæå–å®¢æˆ·ç«¯è´¡çŒ®åº¦ç‰¹å¾ï¼ˆæ”¯æ’‘SAèåˆè´¡çŒ®åº¦è®¡ç®—ï¼‰
        self.extract_client_contribution_features()

        # 8. ä¿å­˜è®­ç»ƒåçš„æœ¬åœ°æ¨¡å‹å‚æ•°ï¼ˆç”¨äºä¸Šä¼ æœåŠ¡ç«¯ï¼‰
        self.trained_local_params = self.local_model.get_params()
        print(f"ğŸ‰ å®¢æˆ·ç«¯ [{self.client_id}] æœ¬åœ°è®­ç»ƒå®Œæˆï¼Œæœ€ä¼˜è®­ç»ƒå‡†ç¡®ç‡ï¼š{max(self.train_metrics['train_acc']):.4f}")

    # ==============================================
    # æ ¸å¿ƒæ–¹æ³•3ï¼šæå–å®¢æˆ·ç«¯è´¡çŒ®åº¦ç‰¹å¾ï¼ˆæ”¯æ’‘Shapley SAè´¡çŒ®åº¦è®¡ç®—ï¼‰
    # ==============================================
    def extract_client_contribution_features(self) -> None:
        """
        æå–å®¢æˆ·ç«¯è´¡çŒ®åº¦æ ¸å¿ƒç‰¹å¾ï¼ˆè°ƒç”¨ALAæ¨¡å—ï¼Œæå–3ç±»ç‰¹å¾ï¼šåå·®ã€ç¨³å®šæ€§ã€æ€§èƒ½ï¼‰
        ç‰¹å¾ç»“æœå­˜å…¥self.client_featuresï¼Œç”¨äºåç»­æœåŠ¡ç«¯SAèåˆè´¡çŒ®åº¦è®¡ç®—
        """
        self.client_features = self.ala_optimizer.extract_ala_features(
            client_id=self.client_id,
            local_model=self.local_model,
            train_metrics=self.train_metrics
        )
        print(f"âœ… å®¢æˆ·ç«¯ [{self.client_id}] å·²æå–SAè´¡çŒ®åº¦ç‰¹å¾ï¼Œç‰¹å¾ç»´åº¦ï¼š{len(self.client_features)}")

    # ==============================================
    # æ ¸å¿ƒæ–¹æ³•4ï¼šä¸Šä¼ æœ¬åœ°ç»“æœï¼ˆç»™æœåŠ¡ç«¯ï¼Œç”¨äºèšåˆä¸è´¡çŒ®åº¦è¯„ä¼°ï¼‰
    # ==============================================
    def upload_local_results(self) -> dict:
        """
        æ•´ç†å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒç»“æœï¼Œä¸Šä¼ è‡³æœåŠ¡ç«¯
        Returns:
            å®¢æˆ·ç«¯æœ¬åœ°ç»“æœå­—å…¸ï¼ˆåŒ…å«æ¨¡å‹å‚æ•°ã€æ ·æœ¬æ•°ã€è´¡çŒ®åº¦ç‰¹å¾ã€è®­ç»ƒæŒ‡æ ‡ï¼‰
        """
        if not self.trained_local_params:
            raise RuntimeError(f"å®¢æˆ·ç«¯ [{self.client_id}] æœªå®Œæˆæœ¬åœ°è®­ç»ƒï¼Œæ— æœ‰æ•ˆç»“æœå¯ä¸Šä¼ ")
        
        upload_data = {
            "client_id": self.client_id,
            "local_params": self.trained_local_params,
            "local_sample_num": self.train_metrics["local_sample_num"],
            "client_features": self.client_features,  # SAè´¡çŒ®åº¦ç‰¹å¾
            "train_metrics": self.train_metrics  # è®­ç»ƒæŸå¤±/å‡†ç¡®ç‡ï¼ˆè¾…åŠ©è¯„ä¼°ï¼‰
        }
        print(f"âœ… å®¢æˆ·ç«¯ [{self.client_id}] å·²æ•´ç†ä¸Šä¼ æ•°æ®ï¼Œå‡†å¤‡å‘é€è‡³æœåŠ¡ç«¯")
        return upload_data

    # ==============================================
    # è¾…åŠ©æ–¹æ³•ï¼šæœ¬åœ°æ¨¡å‹è¯„ä¼°ï¼ˆå¯é€‰ï¼Œç”¨äºå®¢æˆ·ç«¯è‡ªéªŒè¯ï¼‰
    # ==============================================
    def evaluate_local_model(self, test_dataloader=None) -> tuple[float, float]:
        """
        è¯„ä¼°æœ¬åœ°æ¨¡å‹æ€§èƒ½ï¼ˆè‡ªéªŒè¯ï¼Œä¸å½±å“è”é‚¦èšåˆæµç¨‹ï¼‰
        Args:
            test_dataloader: æµ‹è¯•é›†DataLoaderï¼ˆé»˜è®¤ä½¿ç”¨å®¢æˆ·ç«¯æœ¬åœ°éªŒè¯é›†ï¼‰
        Returns:
            avg_loss: å¹³å‡æµ‹è¯•æŸå¤±
            avg_acc: å¹³å‡æµ‹è¯•å‡†ç¡®ç‡
        """
        eval_dataloader = test_dataloader if test_dataloader else self.local_dataloader
        if not eval_dataloader:
            raise ValueError(f"å®¢æˆ·ç«¯ [{self.client_id}] æ— æœ‰æ•ˆè¯„ä¼°æ•°æ®åŠ è½½å™¨")
        
        self.local_model.eval()
        total_loss = 0.0
        total_correct = 0
        total_samples = 0

        with torch.no_grad():
            for images, labels in eval_dataloader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = self.local_model(images)
                loss = self.local_model.loss_fn(outputs, labels)

                total_loss += loss.item() * images.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total_correct += (predicted == labels).sum().item()
                total_samples += images.size(0)

        avg_loss = total_loss / total_samples
        avg_acc = total_correct / total_samples
        print(f"ğŸ“Š å®¢æˆ·ç«¯ [{self.client_id}] æœ¬åœ°æ¨¡å‹è¯„ä¼°ï¼šæŸå¤±={avg_loss:.4f} | å‡†ç¡®ç‡={avg_acc:.4f}")
        return avg_loss, avg_acc