# experiments/basic_performance.py
"""
åŸºç¡€æ€§èƒ½å¯¹æ¯”å®éªŒè„šæœ¬
æ ¸å¿ƒç›®æ ‡ï¼š
1. ç»Ÿä¸€è¿è¡ŒFedAvg/DP-FedAvg/FedProx/Ditto/FedShap 5å¤§åŸºçº¿ç®—æ³•çš„è”é‚¦è®­ç»ƒï¼›
2. è®°å½•æ¯è½®å…¨å±€å‡†ç¡®ç‡ã€å…¨å±€æŸå¤±ã€å®¢æˆ·ç«¯æœ¬åœ°æŸå¤±/å‡†ç¡®ç‡ã€è®­ç»ƒè€—æ—¶ï¼›
3. ä¿å­˜å®éªŒç»“æœï¼ˆCSV/JSONï¼‰ï¼Œç”Ÿæˆæ”¶æ•›æ›²çº¿ã€æœ€ç»ˆæ€§èƒ½å¯¹æ¯”ç­‰å¯è§†åŒ–å›¾è¡¨ï¼›
4. è¾“å‡ºé‡åŒ–å¯¹æ¯”æŠ¥å‘Šï¼Œä¾¿äºåˆ†æå„ç®—æ³•çš„åŸºç¡€æ€§èƒ½å·®å¼‚ã€‚
è®¾è®¡åŸåˆ™ï¼š
- å®Œå…¨å¤ç”¨baselinesæ¨¡å—çš„ç®—æ³•å®ç°ï¼Œä¿è¯å¯¹æ¯”å…¬å¹³æ€§ï¼›
- å¯é…ç½®å®éªŒå‚æ•°ï¼ˆå…¨å±€è½®æ¬¡ã€å®¢æˆ·ç«¯æ•°ã€è®¾å¤‡ç­‰ï¼‰ï¼Œé€‚é…ä¸åŒå®éªŒåœºæ™¯ï¼›
- ç»“æœç»“æ„åŒ–ä¿å­˜ï¼Œæ”¯æŒåç»­å¤ç°å’Œåˆ†æï¼›
- å¯è§†åŒ–ç»“æœç›´è§‚å±•ç¤ºæ”¶æ•›é€Ÿåº¦ã€æœ€ç»ˆæ€§èƒ½å·®å¼‚ã€‚
"""
import os
import time
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from configs.config_loader import load_config
from baselines import (
    FedAvgServer, FedAvgClient,
    DPFedAvgServer, DPFedAvgClient,
    FedProxServer, FedProxClient,
    DittoServer, DittoClient,
    FedShapServer, FedShapClient
)

# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤ºï¼ˆå¯é€‰ï¼‰
plt.rcParams["font.sans-serif"] = ["SimHei"]  # é»‘ä½“
plt.rcParams["axes.unicode_minus"] = False    # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# ======================== å®éªŒé…ç½®å¸¸é‡ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰ ========================
# å¯è§†åŒ–å›¾è¡¨ä¿å­˜æ ¼å¼
PLOT_FORMAT = "png"
# å›¾è¡¨åˆ†è¾¨ç‡
PLOT_DPI = 300
# é¢œè‰²æ˜ å°„ï¼ˆåŒºåˆ†ä¸åŒç®—æ³•ï¼‰
ALGORITHM_COLORS = {
    "FedAvg": "#1f77b4",
    "DP-FedAvg": "#ff7f0e",
    "FedProx": "#2ca02c",
    "Ditto": "#d62728",
    "FedShap": "#9467bd"
}
# æ ‡è®°æ˜ å°„ï¼ˆåŒºåˆ†ä¸åŒç®—æ³•ï¼‰
ALGORITHM_MARKERS = {
    "FedAvg": "o",
    "DP-FedAvg": "s",
    "FedProx": "^",
    "Ditto": "p",
    "FedShap": "*"
}

# ======================== æ ¸å¿ƒå®éªŒç±»ï¼ˆå°è£…å®éªŒé€»è¾‘ï¼‰ ========================
class BasicPerformanceExperiment:
    def __init__(self, config=None, save_results=True, save_path="./experiment_results/basic_performance"):
        """
        åˆå§‹åŒ–åŸºç¡€æ€§èƒ½å¯¹æ¯”å®éªŒ
        Args:
            config: é…ç½®å¯¹è±¡ï¼ˆé»˜è®¤åŠ è½½å…¨å±€é…ç½®ï¼‰
            save_results: æ˜¯å¦ä¿å­˜å®éªŒç»“æœï¼ˆæ•°æ®+å›¾è¡¨ï¼‰
            save_path: ç»“æœä¿å­˜æ ¹ç›®å½•
        """
        # åŠ è½½é…ç½®
        self.config = config if config is not None else load_config()
        # å®éªŒé…ç½®
        self.save_results = save_results
        self.save_path = save_path
        self.device = torch.device(self.config.device)
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        if self.save_results:
            os.makedirs(self.save_path, exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "plots"), exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "data"), exist_ok=True)
        
        # åˆå§‹åŒ–ç®—æ³•åˆ—è¡¨ï¼ˆå¾…è¿è¡Œçš„åŸºçº¿ç®—æ³•ï¼‰
        self.algorithms = [
            {
                "name": "FedAvg",
                "server_cls": FedAvgServer,
                "client_cls": FedAvgClient,
                "requires_global_distribution": False  # æ˜¯å¦éœ€è¦ä¸‹å‘å…¨å±€æ¨¡å‹
            },
            {
                "name": "DP-FedAvg",
                "server_cls": DPFedAvgServer,
                "client_cls": DPFedAvgClient,
                "requires_global_distribution": False
            },
            {
                "name": "FedProx",
                "server_cls": FedProxServer,
                "client_cls": FedProxClient,
                "requires_global_distribution": True  # éœ€è¦ä¸‹å‘å…¨å±€æ¨¡å‹è®¡ç®—è¿‘ç«¯é¡¹
            },
            {
                "name": "Ditto",
                "server_cls": DittoServer,
                "client_cls": DittoClient,
                "requires_global_distribution": True  # éœ€è¦ä¸‹å‘å…¨å±€æ¨¡å‹åˆå§‹åŒ–åŒæ¨¡å‹
            },
            {
                "name": "FedShap",
                "server_cls": FedShapServer,
                "client_cls": FedShapClient,
                "requires_global_distribution": False
            }
        ]
        
        # å®éªŒç»“æœå­˜å‚¨
        self.experiment_results = {
            "global_metrics": {},  # å…¨å±€æŒ‡æ ‡ï¼ˆæ¯è½®å‡†ç¡®ç‡/æŸå¤±/è€—æ—¶ï¼‰
            "client_metrics": {},  # å®¢æˆ·ç«¯æŒ‡æ ‡ï¼ˆæœ€ç»ˆæœ¬åœ°å‡†ç¡®ç‡/æŸå¤±ï¼‰
            "final_summary": {}    # æœ€ç»ˆæ€§èƒ½æ±‡æ€»
        }
        
        print(f"âœ… åŸºç¡€æ€§èƒ½å¯¹æ¯”å®éªŒåˆå§‹åŒ–å®Œæˆ | å¾…è¿è¡Œç®—æ³•ï¼š{[alg['name'] for alg in self.algorithms]}")
        print(f"ğŸ“Œ å®éªŒé…ç½®ï¼šå…¨å±€è½®æ¬¡={self.config.fed.global_rounds} | å®¢æˆ·ç«¯æ•°={self.config.fed.num_clients} | è®¾å¤‡={self.device}")

    def _run_single_algorithm(self, algorithm):
        """
        è¿è¡Œå•ä¸ªç®—æ³•çš„è”é‚¦è®­ç»ƒï¼Œè®°å½•æ ¸å¿ƒæŒ‡æ ‡
        Args:
            algorithm: ç®—æ³•é…ç½®å­—å…¸ï¼ˆname/server_cls/client_cls/requires_global_distributionï¼‰
        Returns:
            algorithm_results: è¯¥ç®—æ³•çš„å®éªŒç»“æœ
        """
        alg_name = algorithm["name"]
        print(f"\n========== å¼€å§‹è¿è¡Œ {alg_name} ==========")
        start_time = time.time()
        
        # 1. åˆå§‹åŒ–æœåŠ¡ç«¯
        server = algorithm["server_cls"](config=self.config)
        server.global_model.to(self.device)
        
        # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
        clients = []
        for client_id in range(self.config.fed.num_clients):
            client = algorithm["client_cls"](client_id=client_id, config=self.config)
            client.local_model.to(self.device)
            clients.append(client)
        
        # ç»‘å®šå®¢æˆ·ç«¯åˆ°æœåŠ¡ç«¯ï¼ˆä¾›åˆ†å‘å…¨å±€æ¨¡å‹/é€‰æ‹©å®¢æˆ·ç«¯ï¼‰
        server.clients = clients
        
        # 3. åˆå§‹åŒ–æŒ‡æ ‡è®°å½•
        global_acc_list = []    # æ¯è½®å…¨å±€å‡†ç¡®ç‡
        global_loss_list = []   # æ¯è½®å…¨å±€æŸå¤±
        round_time_list = []    # æ¯è½®è®­ç»ƒè€—æ—¶
        
        # 4. å¤šè½®è”é‚¦è®­ç»ƒ
        for round_idx in range(self.config.fed.global_rounds):
            round_start = time.time()
            print(f"\n--- {alg_name} å…¨å±€è½®æ¬¡ {round_idx+1}/{self.config.fed.global_rounds} ---")
            
            # 4.1 é€‰æ‹©å®¢æˆ·ç«¯ï¼ˆå¤ç”¨BaseServerçš„éšæœºé€‰æ‹©é€»è¾‘ï¼‰
            selected_cids = server.select_clients(round_idx=round_idx)
            print(f"ğŸ“Œ é€‰ä¸­å®¢æˆ·ç«¯IDï¼š{selected_cids}")
            
            # 4.2 ï¼ˆå¯é€‰ï¼‰ä¸‹å‘å…¨å±€æ¨¡å‹å‚æ•°ï¼ˆFedProx/Dittoéœ€è¦ï¼‰
            if algorithm["requires_global_distribution"]:
                server.distribute_global_model(selected_client_ids=selected_cids)
            
            # 4.3 å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
            client_outputs = []
            for cid in selected_cids:
                client_output = clients[cid].local_train()
                client_outputs.append(client_output)
            
            # 4.4 æœåŠ¡ç«¯èšåˆï¼ˆé€‚é…ä¸åŒç®—æ³•çš„è¾“å‡ºæ ¼å¼ï¼‰
            if alg_name == "FedShap":
                # FedShapå®¢æˆ·ç«¯è¿”å›å­—å…¸ï¼ˆparams+æŒ‡æ ‡ï¼‰ï¼Œç›´æ¥ä¼ å…¥
                server.aggregate_local_results(client_results_list=client_outputs)
            else:
                # å…¶ä»–ç®—æ³•ä»…è¿”å›å‚æ•°åˆ—è¡¨
                client_params = [output for output in client_outputs]
                server.aggregate_local_results(client_params_list=client_params)
            
            # 4.5 è¯„ä¼°å…¨å±€æ¨¡å‹ï¼ˆå¤ç”¨BaseServerçš„è¯„ä¼°é€»è¾‘ï¼‰
            global_acc, global_loss = server.evaluate_global_model()
            global_acc_list.append(global_acc)
            global_loss_list.append(global_loss)
            
            # 4.6 è®°å½•æœ¬è½®è€—æ—¶
            round_time = time.time() - round_start
            round_time_list.append(round_time)
            
            # æ‰“å°æœ¬è½®ç»“æœ
            print(f"ğŸ“Œ {alg_name} è½®æ¬¡ {round_idx+1} | å…¨å±€å‡†ç¡®ç‡ï¼š{global_acc:.2f}% | å…¨å±€æŸå¤±ï¼š{global_loss:.4f} | è€—æ—¶ï¼š{round_time:.2f}s")
        
        # 5. è®°å½•å®¢æˆ·ç«¯æœ€ç»ˆæœ¬åœ°æŒ‡æ ‡
        client_final_metrics = {}
        for cid in range(self.config.fed.num_clients):
            if alg_name == "Ditto":
                # Dittoè¯„ä¼°ä¸ªæ€§åŒ–æ¨¡å‹
                client_acc = clients[cid].evaluate_personal_model()
                client_loss = clients[cid].personal_train_total_loss
            else:
                # å…¶ä»–ç®—æ³•è¯„ä¼°æœ¬åœ°æ¨¡å‹
                client_acc = clients[cid].evaluate_local_model()
                client_loss = clients[cid].local_train_loss
            client_final_metrics[cid] = {
                "acc": client_acc,
                "loss": client_loss
            }
        
        # 6. è®¡ç®—æ€»è€—æ—¶å’Œå¹³å‡è½®æ¬¡è€—æ—¶
        total_time = time.time() - start_time
        avg_round_time = np.mean(round_time_list)
        
        # 7. æ•´ç†è¯¥ç®—æ³•çš„å®éªŒç»“æœ
        algorithm_results = {
            "global_metrics": {
                "acc": global_acc_list,
                "loss": global_loss_list,
                "round_time": round_time_list,
                "total_time": total_time,
                "avg_round_time": avg_round_time
            },
            "client_metrics": client_final_metrics,
            "final_summary": {
                "final_global_acc": global_acc_list[-1],
                "final_global_loss": global_loss_list[-1],
                "avg_client_acc": np.mean([v["acc"] for v in client_final_metrics.values()]),
                "avg_client_loss": np.mean([v["loss"] for v in client_final_metrics.values()]),
                "total_time": total_time,
                "avg_round_time": avg_round_time
            }
        }
        
        print(f"\nâœ… {alg_name} è®­ç»ƒå®Œæˆ | æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡ï¼š{algorithm_results['final_summary']['final_global_acc']:.2f}% | æ€»è€—æ—¶ï¼š{total_time:.2f}s")
        return alg_name, algorithm_results

    def run(self):
        """
        è¿è¡Œæ‰€æœ‰åŸºçº¿ç®—æ³•çš„æ€§èƒ½å¯¹æ¯”å®éªŒï¼Œè®°å½•å¹¶ä¿å­˜ç»“æœ
        """
        # éå†æ‰€æœ‰ç®—æ³•ï¼Œæ‰§è¡Œè®­ç»ƒ
        for algorithm in self.algorithms:
            alg_name, alg_results = self._run_single_algorithm(algorithm)
            self.experiment_results["global_metrics"][alg_name] = alg_results["global_metrics"]
            self.experiment_results["client_metrics"][alg_name] = alg_results["client_metrics"]
            self.experiment_results["final_summary"][alg_name] = alg_results["final_summary"]
        
        # ä¿å­˜å®éªŒç»“æœ
        if self.save_results:
            self._save_results()
            # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            self._generate_plots()
        
        # è¾“å‡ºæœ€ç»ˆå¯¹æ¯”æŠ¥å‘Š
        self._print_final_report()
        
        return self.experiment_results

    def _save_results(self):
        """
        ä¿å­˜å®éªŒç»“æœï¼š
        1. å…¨å±€æŒ‡æ ‡ï¼ˆCSVï¼‰ï¼šæ¯è½®å‡†ç¡®ç‡/æŸå¤±/è€—æ—¶ï¼›
        2. å®¢æˆ·ç«¯æŒ‡æ ‡ï¼ˆJSONï¼‰ï¼šæœ€ç»ˆæœ¬åœ°å‡†ç¡®ç‡/æŸå¤±ï¼›
        3. æœ€ç»ˆæ±‡æ€»ï¼ˆCSV/JSONï¼‰ï¼šæœ€ç»ˆæ€§èƒ½æŒ‡æ ‡ã€‚
        """
        # 1. ä¿å­˜å…¨å±€æŒ‡æ ‡ï¼ˆCSVï¼‰
        global_metrics_df = pd.DataFrame()
        for alg_name, metrics in self.experiment_results["global_metrics"].items():
            # æ„å»ºæ¯è½®çš„DataFrame
            alg_df = pd.DataFrame({
                "round": list(range(1, len(metrics["acc"])+1)),
                "algorithm": alg_name,
                "global_acc": metrics["acc"],
                "global_loss": metrics["loss"],
                "round_time": metrics["round_time"]
            })
            global_metrics_df = pd.concat([global_metrics_df, alg_df], ignore_index=True)
        global_metrics_path = os.path.join(self.save_path, "data", "global_metrics.csv")
        global_metrics_df.to_csv(global_metrics_path, index=False, encoding="utf-8")
        print(f"\nğŸ“ å…¨å±€æŒ‡æ ‡å·²ä¿å­˜è‡³ï¼š{global_metrics_path}")
        
        # 2. ä¿å­˜å®¢æˆ·ç«¯æŒ‡æ ‡ï¼ˆJSONï¼‰
        client_metrics_path = os.path.join(self.save_path, "data", "client_metrics.json")
        with open(client_metrics_path, "w", encoding="utf-8") as f:
            json.dump(self.experiment_results["client_metrics"], f, ensure_ascii=False, indent=4)
        print(f"ğŸ“ å®¢æˆ·ç«¯æŒ‡æ ‡å·²ä¿å­˜è‡³ï¼š{client_metrics_path}")
        
        # 3. ä¿å­˜æœ€ç»ˆæ±‡æ€»ï¼ˆCSV+JSONï¼‰
        final_summary_df = pd.DataFrame.from_dict(self.experiment_results["final_summary"], orient="index")
        final_summary_df.reset_index(inplace=True)
        final_summary_df.rename(columns={"index": "algorithm"}, inplace=True)
        # ä¿å­˜CSV
        final_summary_csv_path = os.path.join(self.save_path, "data", "final_summary.csv")
        final_summary_df.to_csv(final_summary_csv_path, index=False, encoding="utf-8")
        # ä¿å­˜JSON
        final_summary_json_path = os.path.join(self.save_path, "data", "final_summary.json")
        with open(final_summary_json_path, "w", encoding="utf-8") as f:
            json.dump(self.experiment_results["final_summary"], f, ensure_ascii=False, indent=4)
        print(f"ğŸ“ æœ€ç»ˆæ±‡æ€»å·²ä¿å­˜è‡³ï¼š{final_summary_csv_path}")

    def _generate_plots(self):
        """
        ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼š
        1. å…¨å±€å‡†ç¡®ç‡æ”¶æ•›æ›²çº¿ï¼›
        2. å…¨å±€æŸå¤±æ”¶æ•›æ›²çº¿ï¼›
        3. æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾ï¼›
        4. å¹³å‡è½®æ¬¡è€—æ—¶å¯¹æ¯”æŸ±çŠ¶å›¾ã€‚
        """
        # 1. å…¨å±€å‡†ç¡®ç‡æ”¶æ•›æ›²çº¿
        plt.figure(figsize=(10, 6))
        for alg_name, metrics in self.experiment_results["global_metrics"].items():
            rounds = list(range(1, len(metrics["acc"])+1))
            plt.plot(
                rounds, metrics["acc"],
                label=alg_name,
                color=ALGORITHM_COLORS[alg_name],
                marker=ALGORITHM_MARKERS[alg_name],
                markersize=6,
                linewidth=2
            )
        plt.xlabel("å…¨å±€è½®æ¬¡", fontsize=12)
        plt.ylabel("å…¨å±€å‡†ç¡®ç‡ï¼ˆ%ï¼‰", fontsize=12)
        plt.title("å„ç®—æ³•å…¨å±€å‡†ç¡®ç‡æ”¶æ•›æ›²çº¿", fontsize=14, fontweight="bold")
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plot_path = os.path.join(self.save_path, "plots", f"global_acc_convergence.{PLOT_FORMAT}")
        plt.savefig(plot_path, dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        print(f"ğŸ“Š å‡†ç¡®ç‡æ”¶æ•›æ›²çº¿å·²ä¿å­˜è‡³ï¼š{plot_path}")
        
        # 2. å…¨å±€æŸå¤±æ”¶æ•›æ›²çº¿
        plt.figure(figsize=(10, 6))
        for alg_name, metrics in self.experiment_results["global_metrics"].items():
            rounds = list(range(1, len(metrics["loss"])+1))
            plt.plot(
                rounds, metrics["loss"],
                label=alg_name,
                color=ALGORITHM_COLORS[alg_name],
                marker=ALGORITHM_MARKERS[alg_name],
                markersize=6,
                linewidth=2
            )
        plt.xlabel("å…¨å±€è½®æ¬¡", fontsize=12)
        plt.ylabel("å…¨å±€æŸå¤±", fontsize=12)
        plt.title("å„ç®—æ³•å…¨å±€æŸå¤±æ”¶æ•›æ›²çº¿", fontsize=14, fontweight="bold")
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plot_path = os.path.join(self.save_path, "plots", f"global_loss_convergence.{PLOT_FORMAT}")
        plt.savefig(plot_path, dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        print(f"ğŸ“Š æŸå¤±æ”¶æ•›æ›²çº¿å·²ä¿å­˜è‡³ï¼š{plot_path}")
        
        # 3. æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾
        plt.figure(figsize=(10, 6))
        alg_names = list(self.experiment_results["final_summary"].keys())
        final_accs = [self.experiment_results["final_summary"][alg]["final_global_acc"] for alg in alg_names]
        colors = [ALGORITHM_COLORS[alg] for alg in alg_names]
        
        bars = plt.bar(alg_names, final_accs, color=colors, width=0.6)
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨æ•°å€¼
        for bar, acc in zip(bars, final_accs):
            plt.text(
                bar.get_x() + bar.get_width()/2,
                bar.get_height() + 0.5,
                f"{acc:.2f}%",
                ha="center", va="bottom", fontsize=10
            )
        plt.xlabel("ç®—æ³•", fontsize=12)
        plt.ylabel("æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡ï¼ˆ%ï¼‰", fontsize=12)
        plt.title("å„ç®—æ³•æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plot_path = os.path.join(self.save_path, "plots", f"final_global_acc_comparison.{PLOT_FORMAT}")
        plt.savefig(plot_path, dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        print(f"ğŸ“Š æœ€ç»ˆå‡†ç¡®ç‡å¯¹æ¯”å›¾å·²ä¿å­˜è‡³ï¼š{plot_path}")
        
        # 4. å¹³å‡è½®æ¬¡è€—æ—¶å¯¹æ¯”æŸ±çŠ¶å›¾
        plt.figure(figsize=(10, 6))
        avg_round_times = [self.experiment_results["final_summary"][alg]["avg_round_time"] for alg in alg_names]
        bars = plt.bar(alg_names, avg_round_times, color=colors, width=0.6)
        # æ ‡æ³¨æ•°å€¼
        for bar, t in zip(bars, avg_round_times):
            plt.text(
                bar.get_x() + bar.get_width()/2,
                bar.get_height() + 0.1,
                f"{t:.2f}s",
                ha="center", va="bottom", fontsize=10
            )
        plt.xlabel("ç®—æ³•", fontsize=12)
        plt.ylabel("å¹³å‡è½®æ¬¡è€—æ—¶ï¼ˆsï¼‰", fontsize=12)
        plt.title("å„ç®—æ³•å¹³å‡è½®æ¬¡è€—æ—¶å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plot_path = os.path.join(self.save_path, "plots", f"avg_round_time_comparison.{PLOT_FORMAT}")
        plt.savefig(plot_path, dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        print(f"ğŸ“Š å¹³å‡è€—æ—¶å¯¹æ¯”å›¾å·²ä¿å­˜è‡³ï¼š{plot_path}")

    def _print_final_report(self):
        """
        æ‰“å°æœ€ç»ˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Šï¼ˆä¾¿äºå¿«é€ŸæŸ¥çœ‹æ ¸å¿ƒç»“æœï¼‰
        """
        print("\n========== åŸºç¡€æ€§èƒ½å¯¹æ¯”å®éªŒ - æœ€ç»ˆæŠ¥å‘Š ==========")
        print(f"{'ç®—æ³•':<10} {'æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡(%)':<20} {'æœ€ç»ˆå…¨å±€æŸå¤±':<15} {'å¹³å‡å®¢æˆ·ç«¯å‡†ç¡®ç‡(%)':<20} {'æ€»è€—æ—¶(s)':<15} {'å¹³å‡è½®æ¬¡è€—æ—¶(s)':<15}")
        print("-" * 100)
        for alg_name, summary in self.experiment_results["final_summary"].items():
            print(
                f"{alg_name:<10} "
                f"{summary['final_global_acc']:<20.2f} "
                f"{summary['final_global_loss']:<15.4f} "
                f"{summary['avg_client_acc']:<20.2f} "
                f"{summary['total_time']:<15.2f} "
                f"{summary['avg_round_time']:<15.2f}"
            )
        print("-" * 100)

# ======================== å¤–éƒ¨è°ƒç”¨å‡½æ•°ï¼ˆé€‚é…__init__.pyçš„å¯¼å‡ºï¼‰ ========================
def run_basic_performance_experiment(config=None, save_results=True, save_path="./experiment_results/basic_performance"):
    """
    å¤–éƒ¨è°ƒç”¨çš„æ ¸å¿ƒå‡½æ•°ï¼šè¿è¡ŒåŸºç¡€æ€§èƒ½å¯¹æ¯”å®éªŒ
    Args:
        config: é…ç½®å¯¹è±¡ï¼ˆé»˜è®¤åŠ è½½å…¨å±€é…ç½®ï¼‰
        save_results: æ˜¯å¦ä¿å­˜ç»“æœ
        save_path: ç»“æœä¿å­˜è·¯å¾„
    Returns:
        experiment_results: å®éªŒç»“æœå­—å…¸
    """
    # åˆå§‹åŒ–å®éªŒ
    experiment = BasicPerformanceExperiment(config=config, save_results=save_results, save_path=save_path)
    # è¿è¡Œå®éªŒ
    experiment_results = experiment.run()
    return experiment_results

# ======================== ä¸»å‡½æ•°ï¼ˆç›´æ¥è¿è¡Œè„šæœ¬æ—¶æ‰§è¡Œï¼‰ ========================
if __name__ == "__main__":
    # è¿è¡ŒåŸºç¡€æ€§èƒ½å¯¹æ¯”å®éªŒ
    results = run_basic_performance_experiment(
        save_results=True,
        save_path="./experiment_results/basic_performance_2026"
    )
    print("\nâœ… åŸºç¡€æ€§èƒ½å¯¹æ¯”å®éªŒå…¨éƒ¨å®Œæˆï¼")