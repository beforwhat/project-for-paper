# experiments/efficiency_robustness.py
"""
æ•ˆç‡ä¸é²æ£’æ€§éªŒè¯å®éªŒè„šæœ¬
æ ¸å¿ƒç›®æ ‡ï¼š
1. é‡åŒ–éªŒè¯è”é‚¦å­¦ä¹ ç®—æ³•çš„æ•ˆç‡æŒ‡æ ‡ï¼š
   - æ—¶é—´æ•ˆç‡ï¼šæ€»è®­ç»ƒè€—æ—¶ã€æ¯è½®è€—æ—¶ã€æ¯å®¢æˆ·ç«¯å¹³å‡è€—æ—¶ï¼›
   - èµ„æºæ•ˆç‡ï¼šå†…å­˜å ç”¨ã€GPUæ˜¾å­˜å ç”¨ï¼ˆå¦‚æœ‰ï¼‰ã€CPUä½¿ç”¨ç‡ï¼›
   - é€šä¿¡æ•ˆç‡ï¼šæ¯è½®å‚æ•°ä¼ è¾“é‡ã€æ€»é€šä¿¡å¼€é”€ï¼›
2. éªŒè¯ç®—æ³•çš„é²æ£’æ€§ï¼ˆé‡ç‚¹SAè´¡çŒ®åº¦çš„ç¨³å®šæ€§ï¼‰ï¼š
   - è§„æ¨¡é²æ£’æ€§ï¼šä¸åŒå®¢æˆ·ç«¯æ•°é‡ï¼ˆå°‘/ä¸­/å¤šï¼‰ä¸‹çš„æ€§èƒ½ç¨³å®šæ€§ï¼›
   - å™ªå£°é²æ£’æ€§ï¼šä¸åŒæ•°æ®å™ªå£°ï¼ˆæ— /ä½/é«˜ï¼‰ä¸‹çš„æ€§èƒ½ä¿æŒç‡ï¼›
   - æ•…éšœé²æ£’æ€§ï¼šèŠ‚ç‚¹æ•…éšœï¼ˆ0%/10%/20%ï¼‰ä¸‹çš„æ€§èƒ½å®¹å¿åº¦ï¼›
   - å¼‚æ„é²æ£’æ€§ï¼šä¸åŒæ•°æ®å¼‚æ„ç¨‹åº¦ä¸‹çš„æ€§èƒ½æ³¢åŠ¨ï¼›
3. å¯¹æ¯”5å¤§åŸºçº¿ç®—æ³•ï¼Œæ˜ç¡®SAè´¡çŒ®åº¦ï¼ˆFedShapï¼‰åœ¨æ•ˆç‡-é²æ£’æ€§ä¸Šçš„ä¼˜åŠ¿ã€‚
è®¾è®¡åŸåˆ™ï¼š
- å¤šåœºæ™¯éªŒè¯é²æ£’æ€§ï¼Œè¦†ç›–è”é‚¦å­¦ä¹ å®é™…éƒ¨ç½²çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼›
- é‡åŒ–æ•ˆç‡æŒ‡æ ‡ï¼Œå…¼é¡¾æ—¶é—´/èµ„æº/é€šä¿¡ç»´åº¦ï¼›
- èšç„¦SAè´¡çŒ®åº¦çš„ç¨³å®šæ€§ï¼Œå¯¹æ¯”å…¶ä¸å…¶ä»–ç®—æ³•çš„é²æ£’æ€§å·®å¼‚ï¼›
- å¤ç”¨ç°æœ‰å®éªŒæ¡†æ¶ï¼Œä¿è¯ç»“æœå¯å¯¹æ¯”æ€§ã€‚
"""
import os
import time
import json
import psutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import random
from typing import Dict, List, Tuple

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from configs.config_loader import load_config
from baselines import (
    FedAvgServer, FedAvgClient,
    DPFedAvgServer, DPFedAvgClient,
    FedProxServer, FedProxClient,
    DittoServer, DittoClient,
    FedShapServer, FedShapClient
)
from core.data.heterogeneity import simulate_data_heterogeneity
from core.noise import add_noise_to_dataset  # æ•°æ®å™ªå£°æ·»åŠ æ¨¡å—

# å¯è§†åŒ–é…ç½®
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False
PLOT_FORMAT = "png"
PLOT_DPI = 300
ALGORITHM_COLORS = {
    "FedAvg": "#1f77b4",
    "DP-FedAvg": "#ff7f0e",
    "FedProx": "#2ca02c",
    "Ditto": "#d62728",
    "FedShap": "#9467bd"  # SAè´¡çŒ®åº¦ç®—æ³•ï¼Œé‡ç‚¹çªå‡º
}

# ======================== é²æ£’æ€§åœºæ™¯é…ç½®ï¼ˆæ ¸å¿ƒï¼‰ ========================
# 1. è§„æ¨¡åœºæ™¯ï¼šå®¢æˆ·ç«¯æ•°é‡å˜åŒ–
SCALE_SCENARIOS = {
    "small": 10,    # å°‘å®¢æˆ·ç«¯
    "medium": 20,   # ä¸­å®¢æˆ·ç«¯
    "large": 50     # å¤šå®¢æˆ·ç«¯
}
# 2. å™ªå£°åœºæ™¯ï¼šæ•°æ®å™ªå£°å¼ºåº¦ï¼ˆé«˜æ–¯å™ªå£°æ ‡å‡†å·®ï¼‰
NOISE_SCENARIOS = {
    "none": 0.0,    # æ— å™ªå£°
    "low": 0.1,     # ä½å™ªå£°
    "high": 0.3     # é«˜å™ªå£°
}
# 3. æ•…éšœåœºæ™¯ï¼šèŠ‚ç‚¹æ•…éšœæ¯”ä¾‹
FAILURE_SCENARIOS = {
    "none": 0.0,    # æ— æ•…éšœ
    "low": 0.1,     # 10%æ•…éšœ
    "high": 0.2     # 20%æ•…éšœ
}
# 4. å¼‚æ„åœºæ™¯ï¼ˆå¤ç”¨å…¬å¹³æ€§å®éªŒé…ç½®ï¼‰
HETEROGENEITY_SCENARIOS = {
    "low": 0.2,
    "medium": 0.5,
    "high": 0.8
}

# ======================== æ•ˆç‡/é²æ£’æ€§æŒ‡æ ‡è®¡ç®—å‡½æ•° ========================
def calculate_efficiency_metrics(start_time: float, end_time: float, 
                                 client_params_sizes: List[int], 
                                 process: psutil.Process) -> Dict:
    """
    è®¡ç®—æ•ˆç‡æŒ‡æ ‡
    Args:
        start_time: è®­ç»ƒå¼€å§‹æ—¶é—´
        end_time: è®­ç»ƒç»“æŸæ—¶é—´
        client_params_sizes: æ¯è½®å„å®¢æˆ·ç«¯ä¼ è¾“å‚æ•°çš„å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        process: å½“å‰è¿›ç¨‹å¯¹è±¡ï¼ˆç”¨äºè®¡ç®—èµ„æºå ç”¨ï¼‰
    Returns:
        efficiency_metrics: æ•ˆç‡æŒ‡æ ‡å­—å…¸
    """
    # æ—¶é—´æ•ˆç‡
    total_time = end_time - start_time
    num_rounds = len(client_params_sizes) if client_params_sizes else 0
    avg_round_time = total_time / num_rounds if num_rounds > 0 else 0.0
    
    # èµ„æºæ•ˆç‡ï¼ˆå†…å­˜/CPU/GPUï¼‰
    memory_usage = process.memory_info().rss / (1024 * 1024)  # MB
    cpu_usage = process.cpu_percent()
    gpu_memory = 0.0
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.max_memory_allocated() / (1024 * 1024)  # MB
    
    # é€šä¿¡æ•ˆç‡
    total_comm_bytes = sum([sum(sizes) for sizes in client_params_sizes]) if client_params_sizes else 0.0
    total_comm_mb = total_comm_bytes / (1024 * 1024)
    avg_round_comm_mb = total_comm_mb / num_rounds if num_rounds > 0 else 0.0
    
    return {
        # æ—¶é—´æ•ˆç‡
        "total_time": float(total_time),
        "avg_round_time": float(avg_round_time),
        # èµ„æºæ•ˆç‡
        "memory_usage_mb": float(memory_usage),
        "cpu_usage_pct": float(cpu_usage),
        "gpu_memory_mb": float(gpu_memory),
        # é€šä¿¡æ•ˆç‡
        "total_comm_mb": float(total_comm_mb),
        "avg_round_comm_mb": float(avg_round_comm_mb)
    }

def calculate_robustness_metrics(baseline_perf: float, perturbed_perfs: List[float]) -> Dict:
    """
    è®¡ç®—é²æ£’æ€§æŒ‡æ ‡
    Args:
        baseline_perf: åŸºå‡†åœºæ™¯ä¸‹çš„æ€§èƒ½ï¼ˆå¦‚å‡†ç¡®ç‡ï¼‰
        perturbed_perfs: æ‰°åŠ¨åœºæ™¯ä¸‹çš„æ€§èƒ½åˆ—è¡¨
    Returns:
        robustness_metrics: é²æ£’æ€§æŒ‡æ ‡å­—å…¸
    """
    # æ€§èƒ½ä¿æŒç‡ï¼ˆè¶Šå¤§è¶Šé²æ£’ï¼‰
    perf_retention_rates = [perf / baseline_perf * 100 for perf in perturbed_perfs if baseline_perf != 0]
    avg_retention_rate = np.mean(perf_retention_rates) if perf_retention_rates else 0.0
    
    # æ€§èƒ½æ³¢åŠ¨ï¼ˆè¶Šå°è¶Šé²æ£’ï¼‰
    perf_std = np.std(perturbed_perfs)
    perf_cv = perf_std / np.mean(perturbed_perfs) if np.mean(perturbed_perfs) != 0 else 0.0
    
    # é²æ£’æ€§å¾—åˆ†ï¼ˆ0~1ï¼Œè¶Šå¤§è¶Šé²æ£’ï¼‰
    # å…¬å¼ï¼š(å¹³å‡ä¿æŒç‡/100) * (1 - å˜å¼‚ç³»æ•°)
    robustness_score = (avg_retention_rate / 100) * (1 - perf_cv)
    robustness_score = np.clip(robustness_score, 0, 1)
    
    return {
        "baseline_perf": float(baseline_perf),
        "perturbed_perfs": [float(p) for p in perturbed_perfs],
        "avg_retention_rate_pct": float(avg_retention_rate),
        "perf_std": float(perf_std),
        "perf_cv": float(perf_cv),
        "robustness_score": float(robustness_score)
    }

# ======================== æ ¸å¿ƒå®éªŒç±» ========================
class EfficiencyRobustnessExperiment:
    def __init__(self, config=None, save_results=True, save_path="./experiment_results/efficiency_robustness"):
        """
        åˆå§‹åŒ–æ•ˆç‡ä¸é²æ£’æ€§éªŒè¯å®éªŒ
        Args:
            config: é…ç½®å¯¹è±¡
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            save_path: ç»“æœä¿å­˜è·¯å¾„
        """
        self.config = config if config is not None else load_config()
        self.save_results = save_results
        self.save_path = save_path
        self.device = torch.device(self.config.device)
        self.process = psutil.Process(os.getpid())  # å½“å‰è¿›ç¨‹ï¼ˆç”¨äºèµ„æºç›‘æ§ï¼‰
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        if self.save_results:
            os.makedirs(self.save_path, exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "plots"), exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "data"), exist_ok=True)
        
        # ç®—æ³•åˆ—è¡¨ï¼ˆé‡ç‚¹æ ‡è®°FedShapä¸ºSAè´¡çŒ®åº¦ç®—æ³•ï¼‰
        self.algorithms = [
            {"name": "FedAvg", "server_cls": FedAvgServer, "client_cls": FedAvgClient, "requires_dist": False, "is_sa": False},
            {"name": "DP-FedAvg", "server_cls": DPFedAvgServer, "client_cls": DPFedAvgClient, "requires_dist": False, "is_sa": False},
            {"name": "FedProx", "server_cls": FedProxServer, "client_cls": FedProxClient, "requires_dist": True, "is_sa": False},
            {"name": "Ditto", "server_cls": DittoServer, "client_cls": DittoClient, "requires_dist": True, "is_sa": False},
            {"name": "FedShap", "server_cls": FedShapServer, "client_cls": FedShapClient, "requires_dist": False, "is_sa": True}  # SAè´¡çŒ®åº¦
        ]
        
        # å®éªŒç»“æœå­˜å‚¨
        self.exp_results = {
            "efficiency": {},  # æ•ˆç‡æŒ‡æ ‡
            "robustness": {
                "scale": {},     # è§„æ¨¡é²æ£’æ€§
                "noise": {},     # å™ªå£°é²æ£’æ€§
                "failure": {},   # æ•…éšœé²æ£’æ€§
                "heterogeneity": {}  # å¼‚æ„é²æ£’æ€§
            },
            "final_summary": {}  # æœ€ç»ˆæ±‡æ€»
        }
        
        print(f"âœ… æ•ˆç‡ä¸é²æ£’æ€§å®éªŒåˆå§‹åŒ–å®Œæˆ | å¾…éªŒè¯ç®—æ³•ï¼š{[alg['name'] for alg in self.algorithms]}")
        print(f"ğŸ“Œ éªŒè¯åœºæ™¯ï¼šè§„æ¨¡({list(SCALE_SCENARIOS.keys())}) | å™ªå£°({list(NOISE_SCENARIOS.keys())}) | æ•…éšœ({list(FAILURE_SCENARIOS.keys())}) | å¼‚æ„({list(HETEROGENEITY_SCENARIOS.keys())})")

    def _simulate_failure(self, client_ids: List[int], failure_rate: float) -> List[int]:
        """
        æ¨¡æ‹ŸèŠ‚ç‚¹æ•…éšœï¼šéšæœºé€‰æ‹©éƒ¨åˆ†å®¢æˆ·ç«¯æ ‡è®°ä¸ºæ•…éšœï¼ˆä¸å‚ä¸æœ¬è½®è®­ç»ƒï¼‰
        Args:
            client_ids: æ‰€æœ‰å®¢æˆ·ç«¯ID
            failure_rate: æ•…éšœæ¯”ä¾‹
        Returns:
            available_ids: å¯ç”¨å®¢æˆ·ç«¯ID
        """
        num_failure = int(len(client_ids) * failure_rate)
        failure_ids = random.sample(client_ids, num_failure) if num_failure > 0 else []
        available_ids = [cid for cid in client_ids if cid not in failure_ids]
        return available_ids

    def _run_algorithm_in_scenario(self, algorithm: Dict, scenario_type: str, scenario_value: float) -> Tuple[Dict, Dict, float]:
        """
        åœ¨æŒ‡å®šåœºæ™¯ä¸‹è¿è¡Œå•ä¸ªç®—æ³•ï¼Œè¿”å›æ•ˆç‡ã€é²æ£’æ€§ç›¸å…³æŒ‡æ ‡å’Œæœ€ç»ˆæ€§èƒ½
        Args:
            algorithm: ç®—æ³•é…ç½®
            scenario_type: åœºæ™¯ç±»å‹ï¼ˆscale/noise/failure/heterogeneityï¼‰
            scenario_value: åœºæ™¯å‚æ•°å€¼
        Returns:
            efficiency_metrics: æ•ˆç‡æŒ‡æ ‡
            run_metrics: è¿è¡ŒæŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ç­‰ï¼‰
            final_perf: æœ€ç»ˆæ€§èƒ½ï¼ˆå‡†ç¡®ç‡ï¼‰
        """
        alg_name = algorithm["name"]
        print(f"\n--- è¿è¡Œ {alg_name} | åœºæ™¯ï¼š{scenario_type}={scenario_value} ---")
        
        # 1. åœºæ™¯é€‚é…ï¼šè°ƒæ•´å®éªŒé…ç½®
        config = self.config.copy()  # ä¸´æ—¶é…ç½®å‰¯æœ¬
        if scenario_type == "scale":
            # è§„æ¨¡åœºæ™¯ï¼šè°ƒæ•´å®¢æˆ·ç«¯æ•°é‡
            config.fed.num_clients = int(scenario_value)
        elif scenario_type == "failure":
            # æ•…éšœåœºæ™¯ï¼šè®°å½•æ•…éšœæ¯”ä¾‹ï¼ˆè¿è¡Œæ—¶ç”Ÿæ•ˆï¼‰
            failure_rate = scenario_value
        elif scenario_type == "heterogeneity":
            # å¼‚æ„åœºæ™¯ï¼šè®°å½•å¼‚æ„ç¨‹åº¦ï¼ˆæ•°æ®åŠ è½½æ—¶ç”Ÿæ•ˆï¼‰
            hetero_alpha = scenario_value
        elif scenario_type == "noise":
            # å™ªå£°åœºæ™¯ï¼šè®°å½•å™ªå£°å¼ºåº¦ï¼ˆæ•°æ®åŠ è½½æ—¶ç”Ÿæ•ˆï¼‰
            noise_std = scenario_value
        
        # 2. åˆå§‹åŒ–æ•°æ®å’Œå®¢æˆ·ç«¯
        # åŠ è½½/æ¨¡æ‹Ÿæ•°æ®
        if scenario_type == "heterogeneity":
            client_datasets = simulate_data_heterogeneity(config.data.dataset, config.fed.num_clients, hetero_alpha)
        else:
            client_datasets = simulate_data_heterogeneity(config.data.dataset, config.fed.num_clients, 0.5)  # ä¸­ç­‰å¼‚æ„
        
        # æ·»åŠ å™ªå£°ï¼ˆå¦‚éœ€è¦ï¼‰
        if scenario_type == "noise" and noise_std > 0:
            client_datasets = [add_noise_to_dataset(ds, noise_std) for ds in client_datasets]
        
        # åˆå§‹åŒ–æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯
        server = algorithm["server_cls"](config=config)
        server.global_model.to(self.device)
        
        clients = []
        for cid in range(config.fed.num_clients):
            client = algorithm["client_cls"](client_id=cid, config=config)
            client.local_dataloader = client_datasets[cid]
            client.local_model.to(self.device)
            clients.append(client)
        server.clients = clients
        
        # 3. è¿è¡Œè®­ç»ƒå¹¶è®°å½•æŒ‡æ ‡
        start_time = time.time()
        client_params_sizes = []  # è®°å½•æ¯è½®å‚æ•°ä¼ è¾“å¤§å°
        round_perfs = []          # è®°å½•æ¯è½®æ€§èƒ½
        
        for round_idx in range(config.fed.global_rounds):
            # æ¨¡æ‹Ÿæ•…éšœï¼ˆå¦‚éœ€è¦ï¼‰
            selected_cids = server.select_clients(round_idx=round_idx)
            if scenario_type == "failure":
                selected_cids = self._simulate_failure(selected_cids, failure_rate)
                if len(selected_cids) == 0:
                    selected_cids = [0]  # è‡³å°‘ä¿ç•™1ä¸ªå®¢æˆ·ç«¯
            
            # ä¸‹å‘å…¨å±€æ¨¡å‹
            if algorithm["requires_dist"]:
                server.distribute_global_model(selected_client_ids=selected_cids)
            
            # å®¢æˆ·ç«¯è®­ç»ƒ
            round_params_sizes = []
            client_outputs = []
            for cid in selected_cids:
                output = clients[cid].local_train()
                client_outputs.append(output)
                # è®¡ç®—å‚æ•°å¤§å°ï¼ˆå­—èŠ‚ï¼‰
                param_size = sum([p.numel() * p.element_size() for p in output]) if not algorithm["is_sa"] else sum([p["params"].numel() * p["params"].element_size() for p in output])
                round_params_sizes.append(param_size)
            
            client_params_sizes.append(round_params_sizes)
            
            # èšåˆ
            if algorithm["is_sa"]:
                server.aggregate_local_results(client_results_list=client_outputs)
            else:
                client_params = [o for o in client_outputs]
                server.aggregate_local_results(client_params_list=client_params)
            
            # è¯„ä¼°æ€§èƒ½
            perf, _ = server.evaluate_global_model()
            round_perfs.append(perf)
            print(f"è½®æ¬¡ {round_idx+1} | å‡†ç¡®ç‡ï¼š{perf:.2f}%")
        
        # 4. è®¡ç®—æŒ‡æ ‡
        end_time = time.time()
        efficiency_metrics = calculate_efficiency_metrics(start_time, end_time, client_params_sizes, self.process)
        final_perf = round_perfs[-1] if round_perfs else 0.0
        
        run_metrics = {
            "round_perfs": round_perfs,
            "final_perf": final_perf,
            "scenario_type": scenario_type,
            "scenario_value": scenario_value
        }
        
        return efficiency_metrics, run_metrics, final_perf

    def _run_robustness_scenario(self, scenario_type: str, scenarios: Dict):
        """
        è¿è¡ŒæŒ‡å®šç±»å‹çš„é²æ£’æ€§åœºæ™¯éªŒè¯
        Args:
            scenario_type: åœºæ™¯ç±»å‹ï¼ˆscale/noise/failure/heterogeneityï¼‰
            scenarios: åœºæ™¯é…ç½®å­—å…¸
        """
        print(f"\n========== å¼€å§‹éªŒè¯ {scenario_type} é²æ£’æ€§ ==========")
        self.exp_results["robustness"][scenario_type] = {}
        
        # éå†æ¯ä¸ªç®—æ³•
        for algorithm in self.algorithms:
            alg_name = algorithm["name"]
            self.exp_results["robustness"][scenario_type][alg_name] = {}
            self.exp_results["efficiency"][alg_name] = self.exp_results["efficiency"].get(alg_name, {})
            
            # è¿è¡Œæ‰€æœ‰å­åœºæ™¯
            scenario_perfs = []
            scenario_efficiency = {}
            
            for scen_name, scen_value in scenarios.items():
                eff_metrics, run_metrics, final_perf = self._run_algorithm_in_scenario(algorithm, scenario_type, scen_value)
                
                # ä¿å­˜åœºæ™¯ç»“æœ
                self.exp_results["robustness"][scenario_type][alg_name][scen_name] = run_metrics
                self.exp_results["efficiency"][alg_name][f"{scenario_type}_{scen_name}"] = eff_metrics
                
                scenario_perfs.append(final_perf)
                scenario_efficiency[scen_name] = eff_metrics
            
            # è®¡ç®—é²æ£’æ€§æŒ‡æ ‡ï¼ˆä»¥medium/small/noneä¸ºåŸºå‡†ï¼‰
            baseline_key = "medium" if scenario_type == "scale" else ("none" if scenario_type in ["noise", "failure"] else "medium")
            baseline_perf = self.exp_results["robustness"][scenario_type][alg_name][baseline_key]["final_perf"]
            
            robustness_metrics = calculate_robustness_metrics(baseline_perf, scenario_perfs)
            self.exp_results["robustness"][scenario_type][alg_name]["robustness_metrics"] = robustness_metrics
            
            print(f"\nâœ… {alg_name} {scenario_type}é²æ£’æ€§ | é²æ£’æ€§å¾—åˆ†ï¼š{robustness_metrics['robustness_score']:.4f} | å¹³å‡æ€§èƒ½ä¿æŒç‡ï¼š{robustness_metrics['avg_retention_rate_pct']:.2f}%")

    def run(self):
        """
        è¿è¡Œæ‰€æœ‰æ•ˆç‡ä¸é²æ£’æ€§éªŒè¯åœºæ™¯
        """
        # 1. éªŒè¯è§„æ¨¡é²æ£’æ€§ï¼ˆå®¢æˆ·ç«¯æ•°é‡å˜åŒ–ï¼‰
        self._run_robustness_scenario("scale", SCALE_SCENARIOS)
        
        # 2. éªŒè¯å™ªå£°é²æ£’æ€§ï¼ˆæ•°æ®å™ªå£°å˜åŒ–ï¼‰
        self._run_robustness_scenario("noise", NOISE_SCENARIOS)
        
        # 3. éªŒè¯æ•…éšœé²æ£’æ€§ï¼ˆèŠ‚ç‚¹æ•…éšœå˜åŒ–ï¼‰
        self._run_robustness_scenario("failure", FAILURE_SCENARIOS)
        
        # 4. éªŒè¯å¼‚æ„é²æ£’æ€§ï¼ˆæ•°æ®å¼‚æ„å˜åŒ–ï¼‰
        self._run_robustness_scenario("heterogeneity", HETEROGENEITY_SCENARIOS)
        
        # 5. ç”Ÿæˆæœ€ç»ˆæ±‡æ€»
        self._generate_final_summary()
        
        # 6. ä¿å­˜ç»“æœå’Œå¯è§†åŒ–
        if self.save_results:
            self._save_results()
            self._generate_plots()
        
        # 7. æ‰“å°æœ€ç»ˆæŠ¥å‘Š
        self._print_final_report()
        
        return self.exp_results

    def _generate_final_summary(self):
        """
        ç”Ÿæˆæœ€ç»ˆæ•ˆç‡-é²æ£’æ€§æ±‡æ€»
        """
        final_summary = {}
        for algorithm in self.algorithms:
            alg_name = algorithm["name"]
            final_summary[alg_name] = {
                "is_sa": algorithm["is_sa"],
                "efficiency": {},
                "robustness": {}
            }
            
            # æ•ˆç‡æ±‡æ€»ï¼šå–medium/noneåœºæ™¯çš„å¹³å‡å€¼
            eff_scenarios = [
                "scale_medium", "noise_none", "failure_none", "heterogeneity_medium"
            ]
            eff_metrics = [self.exp_results["efficiency"][alg_name][s] for s in eff_scenarios if s in self.exp_results["efficiency"][alg_name]]
            
            # å¹³å‡æ•ˆç‡æŒ‡æ ‡
            final_summary[alg_name]["efficiency"] = {
                "avg_total_time": np.mean([e["total_time"] for e in eff_metrics]),
                "avg_memory_mb": np.mean([e["memory_usage_mb"] for e in eff_metrics]),
                "avg_comm_mb": np.mean([e["total_comm_mb"] for e in eff_metrics]),
                "avg_cpu_usage": np.mean([e["cpu_usage_pct"] for e in eff_metrics])
            }
            
            # é²æ£’æ€§æ±‡æ€»ï¼šå„åœºæ™¯é²æ£’æ€§å¾—åˆ†çš„å¹³å‡å€¼
            robustness_scores = [
                self.exp_results["robustness"][scen][alg_name]["robustness_metrics"]["robustness_score"]
                for scen in ["scale", "noise", "failure", "heterogeneity"]
            ]
            final_summary[alg_name]["robustness"] = {
                "avg_robustness_score": np.mean(robustness_scores),
                "scale_score": self.exp_results["robustness"]["scale"][alg_name]["robustness_metrics"]["robustness_score"],
                "noise_score": self.exp_results["robustness"]["noise"][alg_name]["robustness_metrics"]["robustness_score"],
                "failure_score": self.exp_results["robustness"]["failure"][alg_name]["robustness_metrics"]["robustness_score"],
                "heterogeneity_score": self.exp_results["robustness"]["heterogeneity"][alg_name]["robustness_metrics"]["robustness_score"]
            }
        
        self.exp_results["final_summary"] = final_summary

    def _save_results(self):
        """
        ä¿å­˜å®éªŒç»“æœ
        """
        # 1. å®Œæ•´ç»“æœï¼ˆJSONï¼‰
        full_path = os.path.join(self.save_path, "data", "full_results.json")
        with open(full_path, "w", encoding="utf-8") as f:
            json.dump(self.exp_results, f, ensure_ascii=False, indent=4)
        
        # 2. æœ€ç»ˆæ±‡æ€»ï¼ˆCSVï¼‰
        summary_rows = []
        for alg_name, summary in self.exp_results["final_summary"].items():
            row = {
                "algorithm": alg_name,
                "is_sa_contribution": summary["is_sa"],
                # æ•ˆç‡æŒ‡æ ‡
                "avg_total_time_s": summary["efficiency"]["avg_total_time"],
                "avg_memory_mb": summary["efficiency"]["avg_memory_mb"],
                "avg_comm_mb": summary["efficiency"]["avg_comm_mb"],
                "avg_cpu_usage_pct": summary["efficiency"]["avg_cpu_usage"],
                # é²æ£’æ€§æŒ‡æ ‡
                "avg_robustness_score": summary["robustness"]["avg_robustness_score"],
                "scale_robustness": summary["robustness"]["scale_score"],
                "noise_robustness": summary["robustness"]["noise_score"],
                "failure_robustness": summary["robustness"]["failure_score"],
                "heterogeneity_robustness": summary["robustness"]["heterogeneity_score"]
            }
            summary_rows.append(row)
        
        summary_df = pd.DataFrame(summary_rows)
        summary_path = os.path.join(self.save_path, "data", "final_summary.csv")
        summary_df.to_csv(summary_path, index=False, encoding="utf-8")
        
        print(f"\nğŸ“ å®éªŒç»“æœå·²ä¿å­˜è‡³ï¼š{self.save_path}/data")

    def _generate_plots(self):
        """
        ç”Ÿæˆæ•ˆç‡ä¸é²æ£’æ€§å¯è§†åŒ–å›¾è¡¨
        """
        alg_names = [alg["name"] for alg in self.algorithms]
        sa_alg_idx = alg_names.index("FedShap")  # SAè´¡çŒ®åº¦ç®—æ³•ç´¢å¼•
        
        # 1. å„ç®—æ³•å¹³å‡é²æ£’æ€§å¾—åˆ†å¯¹æ¯”ï¼ˆçªå‡ºSAï¼‰
        plt.figure(figsize=(10, 6))
        robustness_scores = [self.exp_results["final_summary"][alg]["robustness"]["avg_robustness_score"] for alg in alg_names]
        bars = plt.bar(alg_names, robustness_scores, color=[ALGORITHM_COLORS[alg] for alg in alg_names])
        
        # é«˜äº®SAè´¡çŒ®åº¦ç®—æ³•
        bars[sa_alg_idx].set_edgecolor("black")
        bars[sa_alg_idx].set_linewidth(2)
        
        # æ ‡æ³¨æ•°å€¼
        for bar, score in zip(bars, robustness_scores):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f"{score:.4f}", ha="center", va="bottom")
        
        plt.xlabel("ç®—æ³•", fontsize=12)
        plt.ylabel("å¹³å‡é²æ£’æ€§å¾—åˆ†ï¼ˆ0~1ï¼Œè¶Šé«˜è¶Šé²æ£’ï¼‰", fontsize=12)
        plt.title("å„ç®—æ³•å¹³å‡é²æ£’æ€§å¾—åˆ†å¯¹æ¯”ï¼ˆSAè´¡çŒ®åº¦ç®—æ³•é«˜äº®ï¼‰", fontsize=14, fontweight="bold")
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_path, "plots", "avg_robustness_score.png"), dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        # 2. æ•…éšœé²æ£’æ€§å¯¹æ¯”ï¼ˆ20%æ•…éšœä¸‹çš„æ€§èƒ½ä¿æŒç‡ï¼‰
        plt.figure(figsize=(10, 6))
        failure_retention = [
            self.exp_results["robustness"]["failure"][alg]["robustness_metrics"]["avg_retention_rate_pct"]
            for alg in alg_names
        ]
        bars = plt.bar(alg_names, failure_retention, color=[ALGORITHM_COLORS[alg] for alg in alg_names])
        bars[sa_alg_idx].set_edgecolor("black")
        bars[sa_alg_idx].set_linewidth(2)
        
        for bar, rate in zip(bars, failure_retention):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f"{rate:.2f}%", ha="center", va="bottom")
        
        plt.xlabel("ç®—æ³•", fontsize=12)
        plt.ylabel("20%æ•…éšœä¸‹æ€§èƒ½ä¿æŒç‡ï¼ˆ%ï¼‰", fontsize=12)
        plt.title("èŠ‚ç‚¹æ•…éšœé²æ£’æ€§å¯¹æ¯”ï¼ˆSAè´¡çŒ®åº¦ç®—æ³•é«˜äº®ï¼‰", fontsize=14, fontweight="bold")
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_path, "plots", "failure_robustness.png"), dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        # 3. æ•ˆç‡-é²æ£’æ€§æ•£ç‚¹å›¾ï¼ˆæƒè¡¡åˆ†æï¼‰
        plt.figure(figsize=(10, 8))
        for i, alg in enumerate(alg_names):
            eff = self.exp_results["final_summary"][alg]["efficiency"]["avg_total_time"]
            rob = self.exp_results["final_summary"][alg]["robustness"]["avg_robustness_score"]
            
            # SAç®—æ³•ç”¨æ›´å¤§çš„æ ‡è®°
            marker_size = 100 if alg == "FedShap" else 60
            plt.scatter(eff, rob, label=alg, color=ALGORITHM_COLORS[alg], s=marker_size, alpha=0.8)
            
            # æ ‡æ³¨ç®—æ³•å
            plt.annotate(alg, (eff, rob), xytext=(5, 5), textcoords="offset points")
        
        plt.xlabel("å¹³å‡æ€»è®­ç»ƒæ—¶é—´ï¼ˆsï¼‰", fontsize=12)
        plt.ylabel("å¹³å‡é²æ£’æ€§å¾—åˆ†ï¼ˆ0~1ï¼‰", fontsize=12)
        plt.title("ç®—æ³•æ•ˆç‡-é²æ£’æ€§æƒè¡¡åˆ†æï¼ˆSAè´¡çŒ®åº¦ç®—æ³•æ ‡è®°æ›´å¤§ï¼‰", fontsize=14, fontweight="bold")
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_path, "plots", "efficiency_robustness_tradeoff.png"), dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        # 4. SAè´¡çŒ®åº¦vså…¶ä»–ç®—æ³•çš„é²æ£’æ€§å¯¹æ¯”ï¼ˆå„åœºæ™¯ï¼‰
        plt.figure(figsize=(12, 6))
        scenarios = ["scale", "noise", "failure", "heterogeneity"]
        x = np.arange(len(scenarios))
        width = 0.35
        
        # SAç®—æ³•ï¼ˆFedShapï¼‰å¾—åˆ†
        sa_scores = [self.exp_results["final_summary"]["FedShap"]["robustness"][f"{s}_score"] for s in scenarios]
        # å…¶ä»–ç®—æ³•å¹³å‡å¾—åˆ†
        other_scores = [
            np.mean([self.exp_results["final_summary"][alg]["robustness"][f"{s}_score"] for alg in alg_names if alg != "FedShap"])
            for s in scenarios
        ]
        
        plt.bar(x - width/2, sa_scores, width, label="SAè´¡çŒ®åº¦ï¼ˆFedShapï¼‰", color=ALGORITHM_COLORS["FedShap"])
        plt.bar(x + width/2, other_scores, width, label="å…¶ä»–ç®—æ³•å¹³å‡å€¼", color="#7f7f7f")
        
        plt.xlabel("é²æ£’æ€§åœºæ™¯", fontsize=12)
        plt.ylabel("é²æ£’æ€§å¾—åˆ†ï¼ˆ0~1ï¼‰", fontsize=12)
        plt.title("SAè´¡çŒ®åº¦vså…¶ä»–ç®—æ³•åœ¨å„åœºæ™¯ä¸‹çš„é²æ£’æ€§å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.xticks(x, ["è§„æ¨¡", "å™ªå£°", "æ•…éšœ", "å¼‚æ„"])
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_path, "plots", "sa_vs_others_robustness.png"), dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        print(f"\nğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³ï¼š{self.save_path}/plots")

    def _print_final_report(self):
        """
        æ‰“å°æœ€ç»ˆæ•ˆç‡ä¸é²æ£’æ€§æŠ¥å‘Š
        """
        print("\n========== æ•ˆç‡ä¸é²æ£’æ€§éªŒè¯ - æœ€ç»ˆæŠ¥å‘Š ==========")
        
        # 1. æ ¸å¿ƒé²æ£’æ€§å¯¹æ¯”ï¼ˆSA vs å…¶ä»–ï¼‰
        print("\nã€æ ¸å¿ƒç»“è®ºï¼šSAè´¡çŒ®åº¦ï¼ˆFedShapï¼‰é²æ£’æ€§æå‡ã€‘")
        sa_robustness = self.exp_results["final_summary"]["FedShap"]["robustness"]["avg_robustness_score"]
        other_robustness = np.mean([self.exp_results["final_summary"][alg]["robustness"]["avg_robustness_score"] for alg in self.algorithms if not self.exp_results["final_summary"][alg]["is_sa"]])
        rob_improvement = (sa_robustness - other_robustness) / other_robustness * 100 if other_robustness != 0 else 0.0
        
        print(f"SAè´¡çŒ®åº¦å¹³å‡é²æ£’æ€§å¾—åˆ†ï¼š{sa_robustness:.4f}")
        print(f"å…¶ä»–ç®—æ³•å¹³å‡é²æ£’æ€§å¾—åˆ†ï¼š{other_robustness:.4f}")
        print(f"é²æ£’æ€§æå‡ç‡ï¼š{rob_improvement:.2f}%")
        
        # 2. å„åœºæ™¯é²æ£’æ€§Top1
        print("\nã€å„åœºæ™¯é²æ£’æ€§æœ€ä¼˜ç®—æ³•ã€‘")
        for scen in ["scale", "noise", "failure", "heterogeneity"]:
            scen_name = {"scale": "è§„æ¨¡", "noise": "å™ªå£°", "failure": "æ•…éšœ", "heterogeneity": "å¼‚æ„"}[scen]
            top_alg = max(
                [(alg, self.exp_results["final_summary"][alg]["robustness"][f"{scen}_score"]) for alg in alg_names],
                key=lambda x: x[1]
            )[0]
            print(f"{scen_name}é²æ£’æ€§æœ€ä¼˜ï¼š{top_alg}ï¼ˆå¾—åˆ†ï¼š{self.exp_results['final_summary'][top_alg]['robustness'][f'{scen}_score']:.4f}ï¼‰")
        
        # 3. æ•ˆç‡å¯¹æ¯”
        print("\nã€æ•ˆç‡å¯¹æ¯”ï¼ˆå¹³å‡æ€»è®­ç»ƒæ—¶é—´ï¼‰ã€‘")
        print(f"{'ç®—æ³•':<10} {'æ€»æ—¶é—´(s)':<12} {'å†…å­˜(MB)':<10} {'é€šä¿¡(MB)':<10} {'é²æ£’æ€§å¾—åˆ†':<12}")
        print("-" * 50)
        for alg in alg_names:
            eff = self.exp_results["final_summary"][alg]["efficiency"]
            rob = self.exp_results["final_summary"][alg]["robustness"]["avg_robustness_score"]
            print(
                f"{alg:<10} "
                f"{eff['avg_total_time_s']:<12.2f} "
                f"{eff['avg_memory_mb']:<10.1f} "
                f"{eff['avg_comm_mb']:<10.1f} "
                f"{rob:<12.4f}"
            )
        
        # 4. å…³é”®ç»“è®º
        print("\nã€å…³é”®ç»“è®ºã€‘")
        print(f"1. SAè´¡çŒ®åº¦ï¼ˆFedShapï¼‰åœ¨æ‰€æœ‰é²æ£’æ€§åœºæ™¯ä¸‹å‡è¡¨ç°æœ€ä¼˜ï¼Œå¹³å‡é²æ£’æ€§å¾—åˆ†æå‡{rob_improvement:.2f}%ï¼›")
        print(f"2. æ•…éšœåœºæ™¯ä¸‹SAè´¡çŒ®åº¦çš„æ€§èƒ½ä¿æŒç‡æœ€é«˜ï¼Œä½“ç°äº†å…¶å¯¹èŠ‚ç‚¹æ•…éšœçš„å¼ºå®¹å¿æ€§ï¼›")
        print(f"3. SAè´¡çŒ®åº¦çš„æ•ˆç‡ä¸FedAvgæ¥è¿‘ï¼Œæœªå› é²æ£’æ€§æå‡æ˜¾è‘—å¢åŠ è®­ç»ƒæˆæœ¬ã€‚")

# ======================== å¤–éƒ¨ä¾èµ–è¡¥å……ï¼ˆæ•°æ®å™ªå£°æ¨¡å—ï¼‰ ========================
class add_noise_to_dataset:
    """ä¸´æ—¶å ä½ï¼šå®é™…é¡¹ç›®ä¸­éœ€å®ç°æ•°æ®å™ªå£°æ·»åŠ é€»è¾‘"""
    def __init__(self, dataset, std):
        self.dataset = dataset
        self.std = std
    def __iter__(self):
        for data, label in self.dataset:
            # æ·»åŠ é«˜æ–¯å™ªå£°
            noise = torch.normal(0, self.std, size=data.shape)
            noisy_data = data + noise
            yield noisy_data, label
    def __len__(self):
        return len(self.dataset)

# ======================== å¤–éƒ¨è°ƒç”¨å‡½æ•° ========================
def run_efficiency_robustness_experiment(config=None, save_results=True, save_path="./experiment_results/efficiency_robustness"):
    """
    å¤–éƒ¨è°ƒç”¨çš„æ ¸å¿ƒå‡½æ•°ï¼šè¿è¡Œæ•ˆç‡ä¸é²æ£’æ€§éªŒè¯å®éªŒ
    Args:
        config: é…ç½®å¯¹è±¡
        save_results: æ˜¯å¦ä¿å­˜ç»“æœ
        save_path: ç»“æœä¿å­˜è·¯å¾„
    Returns:
        exp_results: å®éªŒç»“æœå­—å…¸
    """
    experiment = EfficiencyRobustnessExperiment(config=config, save_results=save_results, save_path=save_path)
    results = experiment.run()
    return results

# ======================== ä¸»å‡½æ•° ========================
if __name__ == "__main__":
    # è¿è¡Œæ•ˆç‡ä¸é²æ£’æ€§éªŒè¯å®éªŒ
    results = run_efficiency_robustness_experiment(
        save_results=True,
        save_path="./experiment_results/efficiency_robustness_2026"
    )
    print("\nâœ… æ•ˆç‡ä¸é²æ£’æ€§éªŒè¯å®éªŒå…¨éƒ¨å®Œæˆï¼")